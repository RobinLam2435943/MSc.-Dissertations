{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"sdt1cPGxrIS9"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import models, layers, utils, losses, optimizers, initializers, regularizers\nfrom keras.wrappers import scikit_learn\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\nfrom keras.utils import np_utils, image_dataset_from_directory\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix\n\nimport random\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt","metadata":{"id":"kJuXqpDDXskx","scrolled":true,"execution":{"iopub.status.busy":"2023-06-19T19:52:38.432700Z","iopub.execute_input":"2023-06-19T19:52:38.433087Z","iopub.status.idle":"2023-06-19T19:52:41.791372Z","shell.execute_reply.started":"2023-06-19T19:52:38.433057Z","shell.execute_reply":"2023-06-19T19:52:41.790243Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Count the Number of Files, and Take Random Samples from the Image Files","metadata":{"id":"14v7-4Ahre6v"}},{"cell_type":"code","source":"# flist = list(pd.read_csv('flist.txt', header = None)[0])\nflist = list(pd.read_csv('/kaggle/input/dissertation-1-data/Files/flist.txt', header = None)[0])","metadata":{"id":"3490JUu9rPbw","execution":{"iopub.status.busy":"2023-06-19T19:52:41.797679Z","iopub.execute_input":"2023-06-19T19:52:41.798492Z","iopub.status.idle":"2023-06-19T19:52:41.847013Z","shell.execute_reply.started":"2023-06-19T19:52:41.798454Z","shell.execute_reply":"2023-06-19T19:52:41.846194Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Overview of the `properties` Dataset","metadata":{"id":"Wkzy9pS2sATL"}},{"cell_type":"markdown","source":"Read the `properties` dataset first, and make sure that `property type` is a categorical variable.","metadata":{"id":"P45IvHPN3z4m"}},{"cell_type":"code","source":"# properties = pd.read_csv('properties.csv')\n# properties_juny12 = pd.read_csv('properties_juny12.csv')\nproperties = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties.csv')\nproperties_juny12 = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties_juny12.csv')\n\nproperties_full = pd.concat([properties, properties_juny12])\nproperties = properties_full\nproperties.propertyType = properties.propertyType.astype('category')\nproperties.info()","metadata":{"executionInfo":{"elapsed":798,"status":"ok","timestamp":1687082845624,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"0df2eb86-ffd9-4078-f28b-ff5763a8bb66","execution":{"iopub.status.busy":"2023-06-19T19:52:41.848447Z","iopub.execute_input":"2023-06-19T19:52:41.849220Z","iopub.status.idle":"2023-06-19T19:52:42.214216Z","shell.execute_reply.started":"2023-06-19T19:52:41.849187Z","shell.execute_reply":"2023-06-19T19:52:42.213331Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 37402 entries, 0 to 19851\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype   \n---  ------        --------------  -----   \n 0   Unnamed: 0    37402 non-null  int64   \n 1   address       37402 non-null  object  \n 2   propertyType  37402 non-null  category\n 3   bedrooms      24486 non-null  float64 \n 4   detailUrl     37402 non-null  object  \n 5   location_lat  37402 non-null  float64 \n 6   location_lng  37402 non-null  float64 \n 7   property_id   37402 non-null  object  \ndtypes: category(1), float64(3), int64(1), object(3)\nmemory usage: 2.3+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## A Subset of the `properties` Dataset","metadata":{"id":"XDqLkqImshZy"}},{"cell_type":"markdown","source":"As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples.","metadata":{"id":"JOB6YNsm3z4o"}},{"cell_type":"code","source":"flist_id = list(map(lambda string: string[-40 : -4], flist))\nproperties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\nproperties_sub = properties_sub.drop_duplicates(['location_lat', 'location_lng'])\n\n# properties_sub = pd.read_csv('properties_sub.csv')\n# properties_sub = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties_sub.csv')\n\nproperties_sub.propertyType = properties_sub.propertyType.astype('category')\nflist_id = list(properties_sub.property_id)\nproperties_sub.info()","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1687082845627,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj","outputId":"b74717c1-03f8-47ac-dcef-3c0c52daf528","execution":{"iopub.status.busy":"2023-06-19T19:52:42.216760Z","iopub.execute_input":"2023-06-19T19:52:42.219303Z","iopub.status.idle":"2023-06-19T19:52:42.291436Z","shell.execute_reply.started":"2023-06-19T19:52:42.219271Z","shell.execute_reply":"2023-06-19T19:52:42.290351Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 15484 entries, 0 to 19851\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype   \n---  ------        --------------  -----   \n 0   Unnamed: 0    15484 non-null  int64   \n 1   address       15484 non-null  object  \n 2   propertyType  15484 non-null  category\n 3   bedrooms      10967 non-null  float64 \n 4   detailUrl     15484 non-null  object  \n 5   location_lat  15484 non-null  float64 \n 6   location_lng  15484 non-null  float64 \n 7   property_id   15484 non-null  object  \ndtypes: category(1), float64(3), int64(1), object(3)\nmemory usage: 983.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"properties_sub.propertyType.value_counts(sort = False)","metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687082845629,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"vBzsznxg7MEm","outputId":"4db36655-72a0-4be6-f002-a2180e53394d","execution":{"iopub.status.busy":"2023-06-19T19:52:42.295919Z","iopub.execute_input":"2023-06-19T19:52:42.296510Z","iopub.status.idle":"2023-06-19T19:52:42.320295Z","shell.execute_reply.started":"2023-06-19T19:52:42.296479Z","shell.execute_reply":"2023-06-19T19:52:42.319198Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Detached         3337\nFlat             2252\nSemi-Detached    4062\nTerraced         4124\nUnknown          1709\nName: propertyType, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data.","metadata":{"id":"JvcYMSeg3z4p"}},{"cell_type":"code","source":"# directory = 'street_view/'\ndirectory = '/kaggle/input/dissertation-1-data/Files/street_view/'\n\nheight = 64\nwidth = 64\nbatch = 32\n\ntraining = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'training',\n  seed = 123,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\nvalidation = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'validation',\n  seed = 123,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\ntraining = training.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\nvalidation = validation.cache().prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{"executionInfo":{"elapsed":34730,"status":"ok","timestamp":1687082880342,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"2SRMZ9gY3z4p","outputId":"1807b84c-a49a-4d5e-916e-2c166cbaf446","execution":{"iopub.status.busy":"2023-06-19T19:52:42.321566Z","iopub.execute_input":"2023-06-19T19:52:42.321876Z","iopub.status.idle":"2023-06-19T19:52:49.583207Z","shell.execute_reply.started":"2023-06-19T19:52:42.321846Z","shell.execute_reply":"2023-06-19T19:52:49.582151Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 13775 files belonging to 4 classes.\nUsing 9643 files for training.\nFound 13775 files belonging to 4 classes.\nUsing 4132 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"propertyType_train_fac = np.argmax(np.asarray(list(training.unbatch().map(lambda x, y: y))), axis = 1)\npropertyType_validation_fac = np.argmax(np.asarray(list(validation.unbatch().map(lambda x, y: y))), axis = 1)\nlabels = pd.Series(propertyType_train_fac).astype('category')","metadata":{"execution":{"iopub.status.busy":"2023-06-19T19:52:49.584881Z","iopub.execute_input":"2023-06-19T19:52:49.585244Z","iopub.status.idle":"2023-06-19T19:53:05.055509Z","shell.execute_reply.started":"2023-06-19T19:52:49.585210Z","shell.execute_reply":"2023-06-19T19:53:05.054387Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"loss = losses.CategoricalCrossentropy()\nweights = sum(labels.value_counts()) / (labels.value_counts(sort = False) * len(labels.cat.categories))\nloss.weighted = weights","metadata":{"id":"IJJ_9gN73z4q","execution":{"iopub.status.busy":"2023-06-19T19:53:05.057323Z","iopub.execute_input":"2023-06-19T19:53:05.057773Z","iopub.status.idle":"2023-06-19T19:53:05.068669Z","shell.execute_reply.started":"2023-06-19T19:53:05.057732Z","shell.execute_reply":"2023-06-19T19:53:05.067411Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# sample_weights = weights[propertyType_train_fac]\n# training_new = training.unbatch().batch(1).map(lambda x, y: (x, y, sample_weights))","metadata":{"execution":{"iopub.status.busy":"2023-06-19T19:53:05.071078Z","iopub.execute_input":"2023-06-19T19:53:05.072063Z","iopub.status.idle":"2023-06-19T19:53:05.079010Z","shell.execute_reply.started":"2023-06-19T19:53:05.072015Z","shell.execute_reply":"2023-06-19T19:53:05.077991Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"Callbacks = [\n             EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 8, restore_best_weights = True), \n             ReduceLROnPlateau(monitor = 'val_accuracy', factor = 1e-1, patience = 0, cooldown = 0)\n            ]","metadata":{"execution":{"iopub.status.busy":"2023-06-19T19:53:05.083224Z","iopub.execute_input":"2023-06-19T19:53:05.083576Z","iopub.status.idle":"2023-06-19T19:53:05.091144Z","shell.execute_reply.started":"2023-06-19T19:53:05.083543Z","shell.execute_reply":"2023-06-19T19:53:05.090153Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Multi-Class Classification Using Neural Network","metadata":{"id":"CzlhhsNtuQJB"}},{"cell_type":"markdown","source":"### Multi-Layer Perceptron (MLP) model","metadata":{"id":"4yQp9n7C3z4r"}},{"cell_type":"code","source":"# mlp = Sequential([\n#                   Rescaling(1. / 255, input_shape = (height, width, 3)),\n#                   Flatten(),\n#                   Dense(128, activation = tf.nn.leaky_relu),\n#                   Dense(\n#                         len(labels.cat.categories), \n#                         activation = tf.nn.softmax, \n#                         kernel_initializer = 'ones',\n#                         kernel_regularizer = regularizers.L1(.01),\n#                         activity_regularizer = regularizers.L1(.01)\n#                        )\n#                 ])\n# mlp.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n# mlp.summary()","metadata":{"id":"bMonKXA_3z4r","execution":{"iopub.status.busy":"2023-06-19T19:53:05.092733Z","iopub.execute_input":"2023-06-19T19:53:05.093135Z","iopub.status.idle":"2023-06-19T19:53:05.101828Z","shell.execute_reply.started":"2023-06-19T19:53:05.093103Z","shell.execute_reply":"2023-06-19T19:53:05.100770Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# mlp.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"zz6qw9ZvuQJB","execution":{"iopub.status.busy":"2023-06-19T19:53:05.103414Z","iopub.execute_input":"2023-06-19T19:53:05.104013Z","iopub.status.idle":"2023-06-19T19:53:05.115863Z","shell.execute_reply.started":"2023-06-19T19:53:05.103979Z","shell.execute_reply":"2023-06-19T19:53:05.114607Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# propertyType_validation_pred_MLP = np.argmax(mlp.predict(validation), axis = 1)\n# confusion_matrix(propertyType_validation_fac, propertyType_validation_pred_MLP)","metadata":{"id":"HHN3gmu93z4t","execution":{"iopub.status.busy":"2023-06-19T19:53:05.117345Z","iopub.execute_input":"2023-06-19T19:53:05.117732Z","iopub.status.idle":"2023-06-19T19:53:05.126356Z","shell.execute_reply.started":"2023-06-19T19:53:05.117684Z","shell.execute_reply":"2023-06-19T19:53:05.125193Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Convolutional Neural Network (CNN) Model","metadata":{"id":"3mH00TvZ3z4u"}},{"cell_type":"code","source":"cnn = Sequential([\n                  Rescaling(1. / 255, input_shape = (height, width, 3)),\n                  Conv2D(8, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Conv2D(4, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Flatten(),\n                  Dense(16, activation = tf.nn.leaky_relu),\n                  Dropout(.25),\n                  Dense(\n                        len(labels.cat.categories), \n                        activation = tf.nn.softmax, \n                        kernel_initializer = initializers.RandomNormal(),\n                        bias_initializer = initializers.Zeros(),\n                        kernel_regularizer = regularizers.L1(1e-4),\n                        bias_regularizer = regularizers.L1(1),\n                        activity_regularizer = regularizers.L1(1)\n                       )\n                ])\ncnn.compile(loss = loss, optimizer = optimizers.Adam(), metrics = ['accuracy'])\ncnn.summary()","metadata":{"id":"_CwhXPii3z4v","execution":{"iopub.status.busy":"2023-06-19T19:53:05.127562Z","iopub.execute_input":"2023-06-19T19:53:05.129734Z","iopub.status.idle":"2023-06-19T19:53:05.278314Z","shell.execute_reply.started":"2023-06-19T19:53:05.129700Z","shell.execute_reply":"2023-06-19T19:53:05.277529Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling (Rescaling)       (None, 64, 64, 3)         0         \n                                                                 \n conv2d (Conv2D)             (None, 64, 64, 8)         392       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 32, 32, 8)        0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 4)         516       \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 16, 16, 4)        0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1024)              0         \n                                                                 \n dense (Dense)               (None, 16)                16400     \n                                                                 \n dropout (Dropout)           (None, 16)                0         \n                                                                 \n dense_1 (Dense)             (None, 4)                 68        \n                                                                 \n=================================================================\nTotal params: 17,376\nTrainable params: 17,376\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"K63vDgyi3z4v","execution":{"iopub.status.busy":"2023-06-19T19:53:05.279400Z","iopub.execute_input":"2023-06-19T19:53:05.279764Z","iopub.status.idle":"2023-06-19T19:53:39.123431Z","shell.execute_reply.started":"2023-06-19T19:53:05.279728Z","shell.execute_reply":"2023-06-19T19:53:39.122221Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/64\n302/302 [==============================] - 5s 7ms/step - loss: 2.3408 - accuracy: 0.3204 - val_loss: 2.2870 - val_accuracy: 0.3814 - lr: 0.0010\nEpoch 2/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2835 - accuracy: 0.3838 - val_loss: 2.2640 - val_accuracy: 0.3952 - lr: 0.0010\nEpoch 3/64\n302/302 [==============================] - 2s 7ms/step - loss: 2.2656 - accuracy: 0.4001 - val_loss: 2.2519 - val_accuracy: 0.4155 - lr: 0.0010\nEpoch 4/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2473 - accuracy: 0.4167 - val_loss: 2.2419 - val_accuracy: 0.4230 - lr: 0.0010\nEpoch 5/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2376 - accuracy: 0.4227 - val_loss: 2.2360 - val_accuracy: 0.4269 - lr: 0.0010\nEpoch 6/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.2251 - accuracy: 0.4330 - val_loss: 2.2366 - val_accuracy: 0.4303 - lr: 0.0010\nEpoch 7/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2113 - accuracy: 0.4441 - val_loss: 2.2367 - val_accuracy: 0.4247 - lr: 0.0010\nEpoch 8/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1918 - accuracy: 0.4556 - val_loss: 2.2327 - val_accuracy: 0.4301 - lr: 1.0000e-04\nEpoch 9/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1868 - accuracy: 0.4503 - val_loss: 2.2321 - val_accuracy: 0.4315 - lr: 1.0000e-05\nEpoch 10/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1867 - accuracy: 0.4587 - val_loss: 2.2320 - val_accuracy: 0.4305 - lr: 1.0000e-05\nEpoch 11/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1854 - accuracy: 0.4600 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-06\nEpoch 12/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1873 - accuracy: 0.4587 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-07\nEpoch 13/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1861 - accuracy: 0.4602 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-08\nEpoch 14/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1884 - accuracy: 0.4599 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-09\nEpoch 15/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1849 - accuracy: 0.4590 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-10\nEpoch 16/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1871 - accuracy: 0.4543 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-11\nEpoch 17/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.1855 - accuracy: 0.4598 - val_loss: 2.2320 - val_accuracy: 0.4308 - lr: 1.0000e-12\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7bffdf275ba0>"},"metadata":{}}]},{"cell_type":"code","source":"propertyType_validation_pred_CNN = np.argmax(cnn.predict(validation), axis = 1)\nconfusion_matrix(propertyType_validation_fac, propertyType_validation_pred_CNN)","metadata":{"id":"b_txaWaA3z4v","execution":{"iopub.status.busy":"2023-06-19T19:53:39.125087Z","iopub.execute_input":"2023-06-19T19:53:39.125501Z","iopub.status.idle":"2023-06-19T19:53:40.463756Z","shell.execute_reply.started":"2023-06-19T19:53:39.125463Z","shell.execute_reply":"2023-06-19T19:53:40.462793Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"130/130 [==============================] - 1s 2ms/step\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[384,  49, 416, 138],\n       [ 84, 224, 143, 243],\n       [283,  58, 660, 213],\n       [189, 109, 424, 515]])"},"metadata":{}}]}]}