{"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Mount the Drive, and Change to Google Drive Folder","metadata":{"id":"b5mWiul2qpIW"}},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive', force_remount = True)\n\n%cd /content/drive/MyDrive/MSc.-Dissertations/1/Files\n%ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19880,"status":"ok","timestamp":1687082832393,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Tbthf1NQqCI_","outputId":"2a8b1f34-18d8-42c9-ee85-f810d51c1a30"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"id":"sdt1cPGxrIS9"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import models, layers, utils, losses, optimizers, initializers, regularizers\nfrom keras.wrappers import scikit_learn\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\nfrom keras.utils import np_utils, image_dataset_from_directory\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, LambdaCallback\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix\n\nimport random\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt","metadata":{"id":"kJuXqpDDXskx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Count the Number of Files, and Take Random Samples from the Image Files","metadata":{"id":"14v7-4Ahre6v"}},{"cell_type":"code","source":"# !ls street_view\n# count how many files\n# !ls street_view -1 | wc -l\nflist = list(pd.read_csv('flist.txt', header = None)[0])","metadata":{"id":"3490JUu9rPbw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overview of the `properties` Dataset","metadata":{"id":"Wkzy9pS2sATL"}},{"cell_type":"markdown","source":"Read the `properties` dataset first, and make sure that `property type` is a categorical variable.","metadata":{"id":"P45IvHPN3z4m"}},{"cell_type":"code","source":"properties = pd.read_csv('properties.csv')\nproperties_juny12 = pd.read_csv('properties_juny12.csv')\nproperties_full = pd.concat([properties, properties_juny12])\nproperties = properties_full\nproperties.propertyType = properties.propertyType.astype('category')\nproperties.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":798,"status":"ok","timestamp":1687082845624,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"0df2eb86-ffd9-4078-f28b-ff5763a8bb66"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## A Subset of the `properties` Dataset","metadata":{"id":"XDqLkqImshZy"}},{"cell_type":"markdown","source":"As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples.","metadata":{"id":"JOB6YNsm3z4o"}},{"cell_type":"code","source":"flist_id = list(map(lambda string: string[-40 : -4], flist))\nproperties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\nproperties_sub = properties_sub.drop_duplicates(['location_lat', 'location_lng'])\n# properties_sub = pd.read_csv('properties_sub.csv')\nproperties_sub.propertyType = properties_sub.propertyType.astype('category')\nflist_id = list(properties_sub.property_id)\nproperties_sub.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1687082845627,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj","outputId":"b74717c1-03f8-47ac-dcef-3c0c52daf528"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"properties_sub.propertyType.value_counts(sort = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687082845629,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"vBzsznxg7MEm","outputId":"4db36655-72a0-4be6-f002-a2180e53394d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data.","metadata":{"id":"JvcYMSeg3z4p"}},{"cell_type":"code","source":"directory = 'street_view/'\n\nheight = 64\nwidth = 64\nbatch = 32\n\ntraining = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'training',\n  seed = 123,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\nvalidation = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'validation',\n  seed = 123,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\ntraining = training.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\nvalidation = validation.cache().prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34730,"status":"ok","timestamp":1687082880342,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"2SRMZ9gY3z4p","outputId":"1807b84c-a49a-4d5e-916e-2c166cbaf446"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"propertyType_train_fac = np.argmax(np.asarray(list(training.unbatch().map(lambda x, y: y))), axis = 1)\npropertyType_validation_fac = np.argmax(np.asarray(list(validation.unbatch().map(lambda x, y: y))), axis = 1)\nlabels = pd.Series(propertyType_train_fac).astype('category')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = losses.CategoricalCrossentropy()\nweights = sum(labels.value_counts()) / (labels.value_counts(sort = False) * len(labels.cat.categories))\nloss.weighted = weights","metadata":{"id":"IJJ_9gN73z4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample_weights = weights[propertyType_train_fac]\n# training_new = training.unbatch().batch(1).map(lambda x, y: (x, y, sample_weights))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Callbacks = [\n            #  LambdaCallback(on_epoch_end = lambda epoch, logs: print(cnn.layers[-1].get_weights())),\n             EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 8, restore_best_weights = True), \n             ReduceLROnPlateau(monitor = 'val_accuracy', factor = 1e-1, patience = 0, cooldown = 0)\n            ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Multi-Class Classification Using Neural Network","metadata":{"id":"CzlhhsNtuQJB"}},{"cell_type":"markdown","source":"### Multi-Layer Perceptron (MLP) model","metadata":{"id":"4yQp9n7C3z4r"}},{"cell_type":"code","source":"# mlp = Sequential([\n#                   Rescaling(1. / 255, input_shape = (height, width, 3)),\n#                   Flatten(),\n#                   Dense(128, activation = tf.nn.leaky_relu),\n#                   Dense(\n#                         len(labels.cat.categories), \n#                         activation = tf.nn.softmax, \n#                         kernel_initializer = 'ones',\n#                         kernel_regularizer = regularizers.L1(.01),\n#                         activity_regularizer = regularizers.L1(.01)\n#                        )\n#                 ])\n# mlp.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n# mlp.summary()","metadata":{"id":"bMonKXA_3z4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mlp.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"zz6qw9ZvuQJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# propertyType_validation_pred_MLP = np.argmax(mlp.predict(validation), axis = 1)\n# confusion_matrix(propertyType_validation_fac, propertyType_validation_pred_MLP)","metadata":{"id":"HHN3gmu93z4t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convolutional Neural Network","metadata":{"id":"3mH00TvZ3z4u"}},{"cell_type":"code","source":"cnn = Sequential([\n                  Rescaling(1. / 255, input_shape = (height, width, 3)),\n                  Conv2D(8, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(),\n                  Conv2D(4, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(),\n                  Flatten(),\n                  # Dense(16, activation = tf.nn.leaky_relu),\n                  Dropout(.25),\n                  Dense(\n                        len(labels.cat.categories), \n                        activation = tf.nn.softmax, \n                        kernel_initializer = initializers.RandomNormal(),\n                        bias_initializer = initializers.Zeros(),\n                        kernel_regularizer = regularizers.L1(l1 = 1e-4),\n                        bias_regularizer = regularizers.L1(1),\n                        activity_regularizer = regularizers.L1(1)\n                       )\n                ])\ncnn.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\ncnn.summary()","metadata":{"id":"_CwhXPii3z4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"K63vDgyi3z4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"propertyType_validation_pred_CNN = np.argmax(cnn.predict(validation), axis = 1)\nconfusion_matrix(propertyType_validation_fac, propertyType_validation_pred_CNN)","metadata":{"id":"b_txaWaA3z4v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import dill\n# dill.dump_session('Presetting.pkl')\n# # dill.load_session('Presetting.pkl')","metadata":{"id":"vvKahZLh3z4w"},"execution_count":null,"outputs":[]}]}