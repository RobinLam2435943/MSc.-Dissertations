{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports Libraries","metadata":{"id":"sdt1cPGxrIS9"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras import models, layers, utils, losses, optimizers, initializers, regularizers\nfrom keras.wrappers import scikit_learn\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\nfrom keras.utils import np_utils, image_dataset_from_directory\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport random\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt","metadata":{"id":"kJuXqpDDXskx","scrolled":true,"execution":{"iopub.status.busy":"2023-06-20T00:35:25.640249Z","iopub.execute_input":"2023-06-20T00:35:25.640785Z","iopub.status.idle":"2023-06-20T00:35:35.824127Z","shell.execute_reply.started":"2023-06-20T00:35:25.640748Z","shell.execute_reply":"2023-06-20T00:35:35.823074Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reads the `txt` File Specifying the Image File Locations","metadata":{"id":"14v7-4Ahre6v"}},{"cell_type":"code","source":"# flist = list(pd.read_csv('flist.txt', header = None)[0])\nflist = list(pd.read_csv('/kaggle/input/dissertation-1-data/Files/flist.txt', header = None)[0])","metadata":{"id":"3490JUu9rPbw","execution":{"iopub.status.busy":"2023-06-20T00:35:40.477471Z","iopub.execute_input":"2023-06-20T00:35:40.478465Z","iopub.status.idle":"2023-06-20T00:35:40.541040Z","shell.execute_reply.started":"2023-06-20T00:35:40.478421Z","shell.execute_reply":"2023-06-20T00:35:40.540076Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Overview of the `properties` Dataset","metadata":{"id":"Wkzy9pS2sATL"}},{"cell_type":"markdown","source":"Read the `properties` dataset first, and make sure that `property type` is a categorical variable.","metadata":{"id":"P45IvHPN3z4m"}},{"cell_type":"code","source":"# properties = pd.read_csv('properties.csv')\n# properties_juny12 = pd.read_csv('properties_juny12.csv')\nproperties = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties.csv')\nproperties_juny12 = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties_juny12.csv')\n\nproperties_full = pd.concat([properties, properties_juny12])\nproperties = properties_full\nproperties.propertyType = properties.propertyType.astype('category')\nproperties.info()","metadata":{"executionInfo":{"elapsed":798,"status":"ok","timestamp":1687082845624,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"0df2eb86-ffd9-4078-f28b-ff5763a8bb66","execution":{"iopub.status.busy":"2023-06-20T00:35:43.953795Z","iopub.execute_input":"2023-06-20T00:35:43.954300Z","iopub.status.idle":"2023-06-20T00:35:44.356070Z","shell.execute_reply.started":"2023-06-20T00:35:43.954259Z","shell.execute_reply":"2023-06-20T00:35:44.355127Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 37402 entries, 0 to 19851\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype   \n---  ------        --------------  -----   \n 0   Unnamed: 0    37402 non-null  int64   \n 1   address       37402 non-null  object  \n 2   propertyType  37402 non-null  category\n 3   bedrooms      24486 non-null  float64 \n 4   detailUrl     37402 non-null  object  \n 5   location_lat  37402 non-null  float64 \n 6   location_lng  37402 non-null  float64 \n 7   property_id   37402 non-null  object  \ndtypes: category(1), float64(3), int64(1), object(3)\nmemory usage: 2.3+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## A Subset of the `properties` Dataset","metadata":{"id":"XDqLkqImshZy"}},{"cell_type":"markdown","source":"As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples.","metadata":{"id":"JOB6YNsm3z4o"}},{"cell_type":"code","source":"flist_id = list(map(lambda string: string[-40 : -4], flist))\nproperties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\nproperties_sub = properties_sub.drop_duplicates(['location_lat', 'location_lng'])\n\n# properties_sub = pd.read_csv('properties_sub.csv')\n# properties_sub = pd.read_csv('/kaggle/input/dissertation-1-data/Files/properties_sub.csv')\n\nproperties_sub.propertyType = properties_sub.propertyType.astype('category')\nflist_id = list(properties_sub.property_id)\nproperties_sub.info()","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1687082845627,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj","outputId":"b74717c1-03f8-47ac-dcef-3c0c52daf528","execution":{"iopub.status.busy":"2023-06-20T00:35:47.501716Z","iopub.execute_input":"2023-06-20T00:35:47.502072Z","iopub.status.idle":"2023-06-20T00:35:47.558731Z","shell.execute_reply.started":"2023-06-20T00:35:47.502043Z","shell.execute_reply":"2023-06-20T00:35:47.557668Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 15484 entries, 0 to 19851\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype   \n---  ------        --------------  -----   \n 0   Unnamed: 0    15484 non-null  int64   \n 1   address       15484 non-null  object  \n 2   propertyType  15484 non-null  category\n 3   bedrooms      10967 non-null  float64 \n 4   detailUrl     15484 non-null  object  \n 5   location_lat  15484 non-null  float64 \n 6   location_lng  15484 non-null  float64 \n 7   property_id   15484 non-null  object  \ndtypes: category(1), float64(3), int64(1), object(3)\nmemory usage: 983.1+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"properties_sub.propertyType.value_counts(sort = False)","metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1687082845629,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"vBzsznxg7MEm","outputId":"4db36655-72a0-4be6-f002-a2180e53394d","execution":{"iopub.status.busy":"2023-06-20T00:35:50.974898Z","iopub.execute_input":"2023-06-20T00:35:50.975696Z","iopub.status.idle":"2023-06-20T00:35:50.988057Z","shell.execute_reply.started":"2023-06-20T00:35:50.975655Z","shell.execute_reply":"2023-06-20T00:35:50.986849Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Detached         3337\nFlat             2252\nSemi-Detached    4062\nTerraced         4124\nUnknown          1709\nName: propertyType, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data.","metadata":{"id":"JvcYMSeg3z4p"}},{"cell_type":"code","source":"# directory = 'street_view/'\ndirectory = '/kaggle/input/dissertation-1-data/Files/street_view/'\n\nheight = 64\nwidth = 64\nbatch = 32\nseed = np.random.randint(1, np.power(2, 32) - 1)\n\ntraining = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'training',\n  seed = seed,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\nvalidation = image_dataset_from_directory(\n  directory,\n  validation_split = 0.3,\n  subset = 'validation',\n  seed = seed,\n  image_size = (height, width),\n  batch_size = batch,\n  label_mode = 'categorical')\n\ntraining = training.cache().prefetch(buffer_size = tf.data.AUTOTUNE)\nvalidation = validation.cache().prefetch(buffer_size = tf.data.AUTOTUNE)","metadata":{"executionInfo":{"elapsed":34730,"status":"ok","timestamp":1687082880342,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"2SRMZ9gY3z4p","outputId":"1807b84c-a49a-4d5e-916e-2c166cbaf446","execution":{"iopub.status.busy":"2023-06-20T00:35:54.702477Z","iopub.execute_input":"2023-06-20T00:35:54.702831Z","iopub.status.idle":"2023-06-20T00:36:12.244211Z","shell.execute_reply.started":"2023-06-20T00:35:54.702804Z","shell.execute_reply":"2023-06-20T00:36:12.243260Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 13775 files belonging to 4 classes.\nUsing 9643 files for training.\nFound 13775 files belonging to 4 classes.\nUsing 4132 files for validation.\n","output_type":"stream"}]},{"cell_type":"code","source":"propertyType_train_fac = np.argmax(np.asarray(list(training.unbatch().map(lambda x, y: y))), axis = 1)\npropertyType_validation_fac = np.argmax(np.asarray(list(validation.unbatch().map(lambda x, y: y))), axis = 1)\nlabels = pd.Series(propertyType_train_fac).astype('category')","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:36:16.884693Z","iopub.execute_input":"2023-06-20T00:36:16.885060Z","iopub.status.idle":"2023-06-20T00:36:57.283444Z","shell.execute_reply.started":"2023-06-20T00:36:16.885030Z","shell.execute_reply":"2023-06-20T00:36:57.282273Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"loss = losses.CategoricalCrossentropy()\nweights = sum(labels.value_counts()) / (labels.value_counts(sort = False) * len(labels.cat.categories))\nloss.weighted = weights","metadata":{"id":"IJJ_9gN73z4q","execution":{"iopub.status.busy":"2023-06-20T00:37:00.887827Z","iopub.execute_input":"2023-06-20T00:37:00.888195Z","iopub.status.idle":"2023-06-20T00:37:00.897269Z","shell.execute_reply.started":"2023-06-20T00:37:00.888159Z","shell.execute_reply":"2023-06-20T00:37:00.896190Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# sample_weights = weights[propertyType_train_fac]\n# training_new = training.unbatch().batch(1).map(lambda x, y: (x, y, sample_weights))","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:20:21.132774Z","iopub.execute_input":"2023-06-20T00:20:21.133719Z","iopub.status.idle":"2023-06-20T00:20:21.138846Z","shell.execute_reply.started":"2023-06-20T00:20:21.133679Z","shell.execute_reply":"2023-06-20T00:20:21.137691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Callbacks = [\n             EarlyStopping(monitor = 'val_accuracy', mode = 'max', patience = 8, restore_best_weights = True), \n             ReduceLROnPlateau(monitor = 'val_accuracy', factor = 1e-2, patience = 0, cooldown = 0)\n            ]","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:37:04.428447Z","iopub.execute_input":"2023-06-20T00:37:04.428820Z","iopub.status.idle":"2023-06-20T00:37:04.434426Z","shell.execute_reply.started":"2023-06-20T00:37:04.428792Z","shell.execute_reply":"2023-06-20T00:37:04.433240Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Multi-Class Classification Using Neural Network","metadata":{"id":"CzlhhsNtuQJB"}},{"cell_type":"markdown","source":"### Multi-Layer Perceptron (MLP) model","metadata":{"id":"4yQp9n7C3z4r"}},{"cell_type":"code","source":"mlp = Sequential([\n                  Rescaling(1. / 255, input_shape = (height, width, 3)),\n                  Flatten(),\n                  Dense(128, activation = tf.nn.leaky_relu),\n                  Dense(\n                        len(labels.cat.categories), \n                        activation = tf.nn.softmax, \n                        kernel_initializer = initializers.RandomNormal(),\n                        bias_initializer = initializers.Zeros(),\n                        kernel_regularizer = regularizers.L1(1e-4),\n                        bias_regularizer = regularizers.L1(1),\n                        activity_regularizer = regularizers.L1(1)\n                       )\n                ])\nmlp.compile(loss = loss, optimizer = optimizers.Adam(), metrics = ['accuracy'])\nmlp.summary()","metadata":{"id":"bMonKXA_3z4r","execution":{"iopub.status.busy":"2023-06-20T00:37:08.667151Z","iopub.execute_input":"2023-06-20T00:37:08.668030Z","iopub.status.idle":"2023-06-20T00:37:08.790153Z","shell.execute_reply.started":"2023-06-20T00:37:08.667988Z","shell.execute_reply":"2023-06-20T00:37:08.789367Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling (Rescaling)       (None, 64, 64, 3)         0         \n                                                                 \n flatten (Flatten)           (None, 12288)             0         \n                                                                 \n dense (Dense)               (None, 128)               1572992   \n                                                                 \n dense_1 (Dense)             (None, 4)                 516       \n                                                                 \n=================================================================\nTotal params: 1,573,508\nTrainable params: 1,573,508\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"mlp.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"zz6qw9ZvuQJB","execution":{"iopub.status.busy":"2023-06-20T00:37:13.057569Z","iopub.execute_input":"2023-06-20T00:37:13.057921Z","iopub.status.idle":"2023-06-20T00:37:36.298665Z","shell.execute_reply.started":"2023-06-20T00:37:13.057893Z","shell.execute_reply":"2023-06-20T00:37:36.297554Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/64\n302/302 [==============================] - 5s 6ms/step - loss: 2.5337 - accuracy: 0.3317 - val_loss: 2.3079 - val_accuracy: 0.3572 - lr: 0.0010\nEpoch 2/64\n302/302 [==============================] - 1s 4ms/step - loss: 2.3339 - accuracy: 0.3706 - val_loss: 2.3113 - val_accuracy: 0.3722 - lr: 0.0010\nEpoch 3/64\n302/302 [==============================] - 1s 4ms/step - loss: 2.2967 - accuracy: 0.3851 - val_loss: 2.3173 - val_accuracy: 0.3405 - lr: 0.0010\nEpoch 4/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.2247 - accuracy: 0.4540 - val_loss: 2.2648 - val_accuracy: 0.4046 - lr: 1.0000e-05\nEpoch 5/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.2194 - accuracy: 0.4539 - val_loss: 2.2640 - val_accuracy: 0.4030 - lr: 1.0000e-05\nEpoch 6/64\n302/302 [==============================] - 1s 4ms/step - loss: 2.2169 - accuracy: 0.4555 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-07\nEpoch 7/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-09\nEpoch 8/64\n302/302 [==============================] - 1s 4ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-11\nEpoch 9/64\n302/302 [==============================] - 1s 4ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-13\nEpoch 10/64\n302/302 [==============================] - 2s 5ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-15\nEpoch 11/64\n302/302 [==============================] - 1s 5ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-17\nEpoch 12/64\n302/302 [==============================] - 1s 5ms/step - loss: 2.2169 - accuracy: 0.4557 - val_loss: 2.2639 - val_accuracy: 0.4030 - lr: 1.0000e-19\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7aa958e9f430>"},"metadata":{}}]},{"cell_type":"code","source":"propertyType_validation_pred_MLP = np.argmax(mlp.predict(validation), axis = 1)\nconfusion_matrix(propertyType_validation_fac, propertyType_validation_pred_MLP)","metadata":{"id":"HHN3gmu93z4t","execution":{"iopub.status.busy":"2023-06-20T00:37:38.560664Z","iopub.execute_input":"2023-06-20T00:37:38.561065Z","iopub.status.idle":"2023-06-20T00:37:39.004638Z","shell.execute_reply.started":"2023-06-20T00:37:38.561034Z","shell.execute_reply":"2023-06-20T00:37:39.003589Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"130/130 [==============================] - 0s 2ms/step\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[232,  68, 467, 202],\n       [ 50, 212, 146, 259],\n       [154,  70, 636, 358],\n       [116, 135, 435, 592]])"},"metadata":{}}]},{"cell_type":"code","source":"print(\n      classification_report(\n                      propertyType_validation_fac, \n                      propertyType_validation_pred_MLP, \n                      target_names = ['Detached', 'Flat', 'Semi-Detached', 'Terraced']\n      )\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:37:43.182259Z","iopub.execute_input":"2023-06-20T00:37:43.182967Z","iopub.status.idle":"2023-06-20T00:37:43.206731Z","shell.execute_reply.started":"2023-06-20T00:37:43.182930Z","shell.execute_reply":"2023-06-20T00:37:43.205452Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"               precision    recall  f1-score   support\n\n     Detached       0.42      0.24      0.31       969\n         Flat       0.44      0.32      0.37       667\nSemi-Detached       0.38      0.52      0.44      1218\n     Terraced       0.42      0.46      0.44      1278\n\n     accuracy                           0.40      4132\n    macro avg       0.41      0.39      0.39      4132\n weighted avg       0.41      0.40      0.40      4132\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Convolutional Neural Network (CNN) Model","metadata":{"id":"3mH00TvZ3z4u"}},{"cell_type":"code","source":"cnn = Sequential([\n                  Rescaling(1. / 255, input_shape = (height, width, 3)),\n                  Conv2D(8, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Conv2D(4, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Flatten(),\n                  Dense(16, activation = tf.nn.leaky_relu),\n                  Dropout(.25),\n                  Dense(\n                        len(labels.cat.categories), \n                        activation = tf.nn.softmax, \n                        kernel_initializer = initializers.RandomNormal(),\n                        bias_initializer = initializers.Zeros(),\n                        kernel_regularizer = regularizers.L1(1e-4),\n                        bias_regularizer = regularizers.L1(1),\n                        activity_regularizer = regularizers.L1(1)\n                       )\n                ])\ncnn.compile(loss = loss, optimizer = optimizers.Adam(), metrics = ['accuracy'])\ncnn.summary()","metadata":{"id":"_CwhXPii3z4v","execution":{"iopub.status.busy":"2023-06-20T00:37:47.779434Z","iopub.execute_input":"2023-06-20T00:37:47.779804Z","iopub.status.idle":"2023-06-20T00:37:47.897772Z","shell.execute_reply.started":"2023-06-20T00:37:47.779776Z","shell.execute_reply":"2023-06-20T00:37:47.897022Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_1 (Rescaling)     (None, 64, 64, 3)         0         \n                                                                 \n conv2d (Conv2D)             (None, 64, 64, 8)         392       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 32, 32, 8)        0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 32, 32, 4)         516       \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 16, 16, 4)        0         \n 2D)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 16)                16400     \n                                                                 \n dropout (Dropout)           (None, 16)                0         \n                                                                 \n dense_3 (Dense)             (None, 4)                 68        \n                                                                 \n=================================================================\nTotal params: 17,376\nTrainable params: 17,376\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"id":"K63vDgyi3z4v","execution":{"iopub.status.busy":"2023-06-20T00:37:52.140926Z","iopub.execute_input":"2023-06-20T00:37:52.141410Z","iopub.status.idle":"2023-06-20T00:38:32.911896Z","shell.execute_reply.started":"2023-06-20T00:37:52.141372Z","shell.execute_reply":"2023-06-20T00:38:32.910879Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Epoch 1/64\n302/302 [==============================] - 8s 7ms/step - loss: 2.3302 - accuracy: 0.3397 - val_loss: 2.2762 - val_accuracy: 0.3950 - lr: 0.0010\nEpoch 2/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2751 - accuracy: 0.3968 - val_loss: 2.2557 - val_accuracy: 0.4107 - lr: 0.0010\nEpoch 3/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2622 - accuracy: 0.4066 - val_loss: 2.2455 - val_accuracy: 0.4121 - lr: 0.0010\nEpoch 4/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2506 - accuracy: 0.4183 - val_loss: 2.2320 - val_accuracy: 0.4293 - lr: 0.0010\nEpoch 5/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.2385 - accuracy: 0.4292 - val_loss: 2.2251 - val_accuracy: 0.4388 - lr: 0.0010\nEpoch 6/64\n302/302 [==============================] - 2s 8ms/step - loss: 2.2265 - accuracy: 0.4353 - val_loss: 2.2240 - val_accuracy: 0.4395 - lr: 0.0010\nEpoch 7/64\n302/302 [==============================] - 2s 7ms/step - loss: 2.2132 - accuracy: 0.4397 - val_loss: 2.2253 - val_accuracy: 0.4371 - lr: 0.0010\nEpoch 8/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1951 - accuracy: 0.4553 - val_loss: 2.2225 - val_accuracy: 0.4417 - lr: 1.0000e-05\nEpoch 9/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1926 - accuracy: 0.4625 - val_loss: 2.2222 - val_accuracy: 0.4448 - lr: 1.0000e-05\nEpoch 10/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1894 - accuracy: 0.4612 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-05\nEpoch 11/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1916 - accuracy: 0.4600 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-07\nEpoch 12/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1922 - accuracy: 0.4635 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-09\nEpoch 13/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1901 - accuracy: 0.4572 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-11\nEpoch 14/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1883 - accuracy: 0.4601 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-13\nEpoch 15/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1876 - accuracy: 0.4641 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-15\nEpoch 16/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1885 - accuracy: 0.4555 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-17\nEpoch 17/64\n302/302 [==============================] - 2s 6ms/step - loss: 2.1912 - accuracy: 0.4579 - val_loss: 2.2223 - val_accuracy: 0.4441 - lr: 1.0000e-19\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7aa958e9ec50>"},"metadata":{}}]},{"cell_type":"code","source":"propertyType_validation_pred_CNN = np.argmax(cnn.predict(validation), axis = 1)\nconfusion_matrix(propertyType_validation_fac, propertyType_validation_pred_CNN)","metadata":{"id":"b_txaWaA3z4v","execution":{"iopub.status.busy":"2023-06-20T00:38:39.511017Z","iopub.execute_input":"2023-06-20T00:38:39.511594Z","iopub.status.idle":"2023-06-20T00:38:41.827275Z","shell.execute_reply.started":"2023-06-20T00:38:39.511556Z","shell.execute_reply":"2023-06-20T00:38:41.826259Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"130/130 [==============================] - 2s 2ms/step\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"array([[376,  57, 370, 166],\n       [ 93, 229, 113, 232],\n       [253,  58, 624, 283],\n       [177, 123, 369, 609]])"},"metadata":{}}]},{"cell_type":"code","source":"print(\n      classification_report(\n                      propertyType_validation_fac, \n                      propertyType_validation_pred_CNN, \n                      target_names = ['Detached', 'Flat', 'Semi-Detached', 'Terraced']\n      )\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:38:45.226183Z","iopub.execute_input":"2023-06-20T00:38:45.226856Z","iopub.status.idle":"2023-06-20T00:38:45.249902Z","shell.execute_reply.started":"2023-06-20T00:38:45.226823Z","shell.execute_reply":"2023-06-20T00:38:45.248507Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"               precision    recall  f1-score   support\n\n     Detached       0.42      0.39      0.40       969\n         Flat       0.49      0.34      0.40       667\nSemi-Detached       0.42      0.51      0.46      1218\n     Terraced       0.47      0.48      0.47      1278\n\n     accuracy                           0.44      4132\n    macro avg       0.45      0.43      0.44      4132\n weighted avg       0.45      0.44      0.44      4132\n\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn2 = Sequential([\n                  Rescaling(1. / 255, input_shape = (height, width, 3)),\n                  Conv2D(50, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Conv2D(40, 4, padding = 'same', activation = tf.nn.leaky_relu),\n                  MaxPooling2D(pool_size = (2, 2)),\n                  Flatten(),\n                  Dense(40, activation = tf.nn.leaky_relu),\n                  Dropout(.25),\n                  Dense(\n                        len(labels.cat.categories), \n                        activation = tf.nn.softmax, \n                        kernel_initializer = initializers.RandomNormal(),\n                        bias_initializer = initializers.Zeros(),\n                        kernel_regularizer = regularizers.L1(1e-4),\n                        bias_regularizer = regularizers.L1(1),\n                        activity_regularizer = regularizers.L1(1)\n                       )\n                ])\ncnn2.compile(loss = loss, optimizer = optimizers.Adam(), metrics = ['accuracy'])\ncnn2.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:39:18.022095Z","iopub.execute_input":"2023-06-20T00:39:18.022501Z","iopub.status.idle":"2023-06-20T00:39:18.139056Z","shell.execute_reply.started":"2023-06-20T00:39:18.022471Z","shell.execute_reply":"2023-06-20T00:39:18.138304Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n rescaling_2 (Rescaling)     (None, 64, 64, 3)         0         \n                                                                 \n conv2d_2 (Conv2D)           (None, 64, 64, 50)        2450      \n                                                                 \n max_pooling2d_2 (MaxPooling  (None, 32, 32, 50)       0         \n 2D)                                                             \n                                                                 \n conv2d_3 (Conv2D)           (None, 32, 32, 40)        32040     \n                                                                 \n max_pooling2d_3 (MaxPooling  (None, 16, 16, 40)       0         \n 2D)                                                             \n                                                                 \n flatten_2 (Flatten)         (None, 10240)             0         \n                                                                 \n dense_4 (Dense)             (None, 40)                409640    \n                                                                 \n dropout_1 (Dropout)         (None, 40)                0         \n                                                                 \n dense_5 (Dense)             (None, 4)                 164       \n                                                                 \n=================================================================\nTotal params: 444,294\nTrainable params: 444,294\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"cnn2.fit(training, validation_data = validation, epochs = 64, batch_size = 64, callbacks = Callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:39:24.865256Z","iopub.execute_input":"2023-06-20T00:39:24.865620Z","iopub.status.idle":"2023-06-20T00:40:30.824243Z","shell.execute_reply.started":"2023-06-20T00:39:24.865594Z","shell.execute_reply":"2023-06-20T00:40:30.823135Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/64\n302/302 [==============================] - 4s 11ms/step - loss: 2.3023 - accuracy: 0.3620 - val_loss: 2.2505 - val_accuracy: 0.4105 - lr: 0.0010\nEpoch 2/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.2529 - accuracy: 0.4165 - val_loss: 2.2353 - val_accuracy: 0.4279 - lr: 0.0010\nEpoch 3/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.2269 - accuracy: 0.4386 - val_loss: 2.2264 - val_accuracy: 0.4337 - lr: 0.0010\nEpoch 4/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.2042 - accuracy: 0.4465 - val_loss: 2.2230 - val_accuracy: 0.4429 - lr: 0.0010\nEpoch 5/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.1747 - accuracy: 0.4666 - val_loss: 2.2353 - val_accuracy: 0.4315 - lr: 0.0010\nEpoch 6/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.1177 - accuracy: 0.5040 - val_loss: 2.2187 - val_accuracy: 0.4441 - lr: 1.0000e-05\nEpoch 7/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.1093 - accuracy: 0.5035 - val_loss: 2.2211 - val_accuracy: 0.4470 - lr: 1.0000e-05\nEpoch 8/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.1017 - accuracy: 0.5072 - val_loss: 2.2241 - val_accuracy: 0.4487 - lr: 1.0000e-05\nEpoch 9/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0993 - accuracy: 0.5096 - val_loss: 2.2268 - val_accuracy: 0.4492 - lr: 1.0000e-05\nEpoch 10/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0926 - accuracy: 0.5116 - val_loss: 2.2289 - val_accuracy: 0.4511 - lr: 1.0000e-05\nEpoch 11/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0912 - accuracy: 0.5153 - val_loss: 2.2300 - val_accuracy: 0.4511 - lr: 1.0000e-05\nEpoch 12/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0883 - accuracy: 0.5148 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-07\nEpoch 13/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0897 - accuracy: 0.5160 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-09\nEpoch 14/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0903 - accuracy: 0.5143 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-11\nEpoch 15/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0860 - accuracy: 0.5150 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-13\nEpoch 16/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0863 - accuracy: 0.5190 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-15\nEpoch 17/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0884 - accuracy: 0.5131 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-17\nEpoch 18/64\n302/302 [==============================] - 3s 10ms/step - loss: 2.0878 - accuracy: 0.5182 - val_loss: 2.2300 - val_accuracy: 0.4509 - lr: 1.0000e-19\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7aa9305dda80>"},"metadata":{}}]},{"cell_type":"code","source":"propertyType_validation_pred_CNN2 = np.argmax(cnn2.predict(validation), axis = 1)\nconfusion_matrix(propertyType_validation_fac, propertyType_validation_pred_CNN2)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:40:37.600590Z","iopub.execute_input":"2023-06-20T00:40:37.600973Z","iopub.status.idle":"2023-06-20T00:40:38.214273Z","shell.execute_reply.started":"2023-06-20T00:40:37.600941Z","shell.execute_reply":"2023-06-20T00:40:38.213267Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"130/130 [==============================] - 1s 4ms/step\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([[378,  66, 384, 141],\n       [ 96, 269, 134, 168],\n       [254,  74, 640, 250],\n       [174, 119, 408, 577]])"},"metadata":{}}]},{"cell_type":"code","source":"print(\n      classification_report(\n                      propertyType_validation_fac, \n                      propertyType_validation_pred_CNN2, \n                      target_names = ['Detached', 'Flat', 'Semi-Detached', 'Terraced']\n      )\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-20T00:40:41.700915Z","iopub.execute_input":"2023-06-20T00:40:41.701288Z","iopub.status.idle":"2023-06-20T00:40:41.722735Z","shell.execute_reply.started":"2023-06-20T00:40:41.701257Z","shell.execute_reply":"2023-06-20T00:40:41.721627Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"               precision    recall  f1-score   support\n\n     Detached       0.42      0.39      0.40       969\n         Flat       0.51      0.40      0.45       667\nSemi-Detached       0.41      0.53      0.46      1218\n     Terraced       0.51      0.45      0.48      1278\n\n     accuracy                           0.45      4132\n    macro avg       0.46      0.44      0.45      4132\n weighted avg       0.46      0.45      0.45      4132\n\n","output_type":"stream"}]}]}