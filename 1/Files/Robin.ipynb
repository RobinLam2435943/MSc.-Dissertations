{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"b5mWiul2qpIW"},"source":["## Mount the Drive, and Change to Google Drive Folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20292,"status":"ok","timestamp":1685703332650,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Tbthf1NQqCI_","outputId":"0523dfd5-044d-40e2-ba09-211cfed04eb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount = True)\n","\n","# %cd /content/drive/MyDrive/MSc.-Dissertations/1/Files\n","# %ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sdt1cPGxrIS9"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4983,"status":"ok","timestamp":1685703337623,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"kJuXqpDDXskx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import models, layers, utils, losses\n","from keras.wrappers import scikit_learn\n","from keras.models import *\n","from keras.layers import *\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from keras.utils import np_utils\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix\n","\n","import random\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"14v7-4Ahre6v"},"source":["## Count the Number of Files, and Take Random Samples from the Image Files"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1685703337958,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"3490JUu9rPbw"},"outputs":[],"source":["# !ls street_view\n","# count how many files and write the filenames into a file\n","# !ls street_view -1 | wc -l \n","# !ls street_view/*.jpg > flist.txt\n","flist = list(pd.read_csv('flist.txt', header = None)[0])\n","\n","# Set seed so sample is reproducible \n","# random.seed(99)  # set this to an integer value!!!\n","# nsamp = 100\n","# flist_sub = random.sample(flist, nsamp)\n","# flist = flist_sub\n","\n","# print(flist)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wkzy9pS2sATL"},"source":["## Overview of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Read the `properties` dataset first, and make sure that `property type` is a categorical variable."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1685703338269,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"82aa5d04-bd88-4520-b79f-23c955888237"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>address</th>\n","      <th>propertyType</th>\n","      <th>bedrooms</th>\n","      <th>detailUrl</th>\n","      <th>location_lat</th>\n","      <th>location_lng</th>\n","      <th>property_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...</td>\n","      <td>Terraced</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29986</td>\n","      <td>-1.49446</td>\n","      <td>60d9dd15-c5a0-4d9c-a341-a1d47add49d5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>5, Highgate Lane, Dronfield, Derbyshire S18 1UB</td>\n","      <td>Detached</td>\n","      <td>4.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29135</td>\n","      <td>-1.45975</td>\n","      <td>4a586e80-181a-4b82-b5c3-2d789436bb14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>125, Gosforth Lane, Dronfield, Derbyshire S18 1RB</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29763</td>\n","      <td>-1.47573</td>\n","      <td>93680b6c-237e-44d3-8f40-959a14b80cad</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>80, Shakespeare Crescent, Dronfield, Derbyshir...</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29259</td>\n","      <td>-1.45644</td>\n","      <td>5d49758b-f148-4d06-bbae-3eb23f5c68fb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>21, Gainsborough Road, Dronfield, Derbyshire S...</td>\n","      <td>Detached</td>\n","      <td>NaN</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29740</td>\n","      <td>-1.48503</td>\n","      <td>4645f5eb-de7c-474f-8d7e-b59fa8c55f19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                            address propertyType  \\\n","0           0  12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...     Terraced   \n","1           0    5, Highgate Lane, Dronfield, Derbyshire S18 1UB     Detached   \n","2           0  125, Gosforth Lane, Dronfield, Derbyshire S18 1RB     Detached   \n","3           0  80, Shakespeare Crescent, Dronfield, Derbyshir...     Detached   \n","4           0  21, Gainsborough Road, Dronfield, Derbyshire S...     Detached   \n","\n","   bedrooms                                          detailUrl  location_lat  \\\n","0       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29986   \n","1       4.0  https://www.rightmove.co.uk/house-prices/detai...      53.29135   \n","2       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29763   \n","3       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29259   \n","4       NaN  https://www.rightmove.co.uk/house-prices/detai...      53.29740   \n","\n","   location_lng                           property_id  \n","0      -1.49446  60d9dd15-c5a0-4d9c-a341-a1d47add49d5  \n","1      -1.45975  4a586e80-181a-4b82-b5c3-2d789436bb14  \n","2      -1.47573  93680b6c-237e-44d3-8f40-959a14b80cad  \n","3      -1.45644  5d49758b-f148-4d06-bbae-3eb23f5c68fb  \n","4      -1.48503  4645f5eb-de7c-474f-8d7e-b59fa8c55f19  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["properties = pd.read_csv('properties.csv')\n","properties.propertyType = properties.propertyType.astype('category')\n","properties.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Basic information of the dataset is shown as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1685703338661,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zFHpWHe8ndW6","outputId":"a9a60486-f56c-41ca-d447-5e36dc1dcb3e"},"outputs":[],"source":["properties.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Descriptive statistics of continuous variables are shown as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685703338662,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"8ser64Zzm7Km","outputId":"e959f663-769b-4db4-a546-9201e2fa3f63"},"outputs":[],"source":["properties.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Frequencies of each level of the variable `property type` are obtained as follows."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685703338663,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"mMG-qHT_8rSr","outputId":"b2ad2fb9-4014-450e-e954-215b4e64db2a"},"outputs":[],"source":["properties.propertyType.value_counts()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XDqLkqImshZy"},"source":["## A Subset of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685703338664,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj"},"outputs":[],"source":["flist_id = list(map(lambda string: string[16 : -4], flist))\n","properties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\n","properties_sub = properties_sub.drop_duplicates(['address', 'detailUrl', 'location_lat', 'location_lng'])\n","flist_id = list(properties_sub.property_id)\n","flist_new = []\n","temp = list(map(lambda x: flist_new.append(f'street_view/gsv_{x}.jpg'), flist_id))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Dictionaries are created to link `property ID` with our variables of interest."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":146820,"status":"ok","timestamp":1685703485474,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"ZdHCLGjmuQJA"},"outputs":[],"source":["# dic_propID_imgArray = dict(zip(flist_id, list(map(lambda x: np.array(Image.open(x)), flist_new)))) # dictionary of RGB values in each pixel\n","# dic_propID_propType = dict(zip(flist_id, properties_sub.propertyType)) # dictionary of property types"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["Img_array_train, Img_array_test, propertyType_train, propertyType_test = train_test_split(\n","    np.array(list(map(lambda x: np.array(Image.open(x)), flist_new))), # RGB values in each pixel\n","    np.array(properties_sub.propertyType), # property types\n","    test_size = 0.3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["For categorical variables, one-hot encoder is introduced."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":70,"status":"ok","timestamp":1685703485477,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"_bFYcWMtuQJA"},"outputs":[],"source":["dummy_propertyType_train = pd.get_dummies(propertyType_train)\n","dummy_propertyType_test = pd.get_dummies(propertyType_test)\n","propertyType_test_fac = np.argmax(np.array(dummy_propertyType_test), axis = 1) "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CzlhhsNtuQJB"},"source":["## Multi-Class Classification Using Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Multi-Layer Perceptron (MLP) model"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1685703485479,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"cVOv_GReuQJB"},"outputs":[],"source":["def mlp(output_dim):\n","\n","    '''\n","    Creates a multi-layer perceptron neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Flatten())\n","    # model.add(Dense(100, activation = tf.nn.leaky_relu))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6071,"status":"ok","timestamp":1685703491525,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zz6qw9ZvuQJB","outputId":"533c854e-87ca-4e7e-c441-1391c50bff64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","7/7 [==============================] - 1s 114ms/step - loss: 147.5202 - accuracy: 0.1836\n","Epoch 2/100\n","7/7 [==============================] - 1s 103ms/step - loss: 157.5188 - accuracy: 0.2492\n","Epoch 3/100\n","7/7 [==============================] - 1s 120ms/step - loss: 85.5925 - accuracy: 0.2033\n","Epoch 4/100\n","7/7 [==============================] - 1s 103ms/step - loss: 59.2720 - accuracy: 0.2984\n","Epoch 5/100\n","7/7 [==============================] - 1s 103ms/step - loss: 63.3905 - accuracy: 0.2820\n","Epoch 6/100\n","7/7 [==============================] - 1s 100ms/step - loss: 27.2860 - accuracy: 0.3377\n","Epoch 7/100\n","7/7 [==============================] - 1s 99ms/step - loss: 20.2335 - accuracy: 0.3770\n","Epoch 8/100\n","7/7 [==============================] - 1s 100ms/step - loss: 13.5945 - accuracy: 0.3803\n","Epoch 9/100\n","7/7 [==============================] - 1s 103ms/step - loss: 12.0764 - accuracy: 0.4623\n","Epoch 10/100\n","7/7 [==============================] - 1s 97ms/step - loss: 10.2137 - accuracy: 0.4492\n","Epoch 11/100\n","7/7 [==============================] - 1s 91ms/step - loss: 9.7915 - accuracy: 0.4197\n","Epoch 12/100\n","7/7 [==============================] - 1s 87ms/step - loss: 10.8875 - accuracy: 0.4033\n","Epoch 13/100\n","7/7 [==============================] - 1s 88ms/step - loss: 15.5126 - accuracy: 0.5016\n","Epoch 14/100\n","7/7 [==============================] - 1s 96ms/step - loss: 14.1841 - accuracy: 0.5279\n","Epoch 15/100\n","7/7 [==============================] - 1s 96ms/step - loss: 16.9324 - accuracy: 0.4852\n","Epoch 16/100\n","7/7 [==============================] - 1s 106ms/step - loss: 14.0575 - accuracy: 0.4623\n","Epoch 17/100\n","7/7 [==============================] - 1s 110ms/step - loss: 19.7761 - accuracy: 0.3541\n","Epoch 18/100\n","7/7 [==============================] - 1s 88ms/step - loss: 13.6642 - accuracy: 0.5115\n","Epoch 19/100\n","7/7 [==============================] - 1s 88ms/step - loss: 4.5435 - accuracy: 0.6623\n","Epoch 20/100\n","7/7 [==============================] - 1s 88ms/step - loss: 2.8648 - accuracy: 0.7115\n","Epoch 21/100\n","7/7 [==============================] - 1s 88ms/step - loss: 2.5029 - accuracy: 0.6918\n","Epoch 22/100\n","7/7 [==============================] - 1s 87ms/step - loss: 2.7623 - accuracy: 0.6885\n","Epoch 23/100\n","7/7 [==============================] - 1s 92ms/step - loss: 5.5685 - accuracy: 0.6131\n","Epoch 24/100\n","7/7 [==============================] - 1s 88ms/step - loss: 2.8700 - accuracy: 0.7246\n","Epoch 25/100\n","7/7 [==============================] - 1s 87ms/step - loss: 4.1750 - accuracy: 0.6426\n","Epoch 26/100\n","7/7 [==============================] - 1s 88ms/step - loss: 4.8508 - accuracy: 0.6197\n","Epoch 27/100\n","7/7 [==============================] - 1s 87ms/step - loss: 1.7796 - accuracy: 0.7574\n","Epoch 28/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.5418 - accuracy: 0.8918\n","Epoch 29/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.6898 - accuracy: 0.8820\n","Epoch 30/100\n","7/7 [==============================] - 1s 93ms/step - loss: 0.6721 - accuracy: 0.9016\n","Epoch 31/100\n","7/7 [==============================] - 1s 92ms/step - loss: 0.9570 - accuracy: 0.8557\n","Epoch 32/100\n","7/7 [==============================] - 1s 88ms/step - loss: 0.8124 - accuracy: 0.8590\n","Epoch 33/100\n","7/7 [==============================] - 1s 88ms/step - loss: 1.6573 - accuracy: 0.7607\n","Epoch 34/100\n","7/7 [==============================] - 1s 91ms/step - loss: 5.8657 - accuracy: 0.5902\n","Epoch 35/100\n","7/7 [==============================] - 1s 87ms/step - loss: 7.0885 - accuracy: 0.6164\n","Epoch 36/100\n","7/7 [==============================] - 1s 88ms/step - loss: 4.6767 - accuracy: 0.6656\n","Epoch 37/100\n","7/7 [==============================] - 1s 85ms/step - loss: 4.1884 - accuracy: 0.7607\n","Epoch 38/100\n","7/7 [==============================] - 1s 87ms/step - loss: 2.2098 - accuracy: 0.7738\n","Epoch 39/100\n","7/7 [==============================] - 1s 89ms/step - loss: 4.7751 - accuracy: 0.6590\n","Epoch 40/100\n","7/7 [==============================] - 1s 88ms/step - loss: 3.8024 - accuracy: 0.7803\n","Epoch 41/100\n","7/7 [==============================] - 1s 88ms/step - loss: 4.7999 - accuracy: 0.7049\n","Epoch 42/100\n","7/7 [==============================] - 1s 88ms/step - loss: 8.2488 - accuracy: 0.6656\n","Epoch 43/100\n","7/7 [==============================] - 1s 85ms/step - loss: 10.1718 - accuracy: 0.6295\n","Epoch 44/100\n","7/7 [==============================] - 1s 87ms/step - loss: 2.4545 - accuracy: 0.7934\n","Epoch 45/100\n","7/7 [==============================] - 1s 86ms/step - loss: 2.2838 - accuracy: 0.7967\n","Epoch 46/100\n","7/7 [==============================] - 1s 94ms/step - loss: 2.4213 - accuracy: 0.8230\n","Epoch 47/100\n","7/7 [==============================] - 1s 92ms/step - loss: 2.2763 - accuracy: 0.8131\n","Epoch 48/100\n","7/7 [==============================] - 1s 89ms/step - loss: 1.6961 - accuracy: 0.8131\n","Epoch 49/100\n","7/7 [==============================] - 1s 88ms/step - loss: 3.7558 - accuracy: 0.7475\n","Epoch 50/100\n","7/7 [==============================] - 1s 86ms/step - loss: 1.2443 - accuracy: 0.8721\n","Epoch 51/100\n","7/7 [==============================] - 1s 87ms/step - loss: 5.7494 - accuracy: 0.6459\n","Epoch 52/100\n","7/7 [==============================] - 1s 95ms/step - loss: 4.1320 - accuracy: 0.7180\n","Epoch 53/100\n","7/7 [==============================] - 1s 94ms/step - loss: 5.4038 - accuracy: 0.7180\n","Epoch 54/100\n","7/7 [==============================] - 1s 95ms/step - loss: 5.6985 - accuracy: 0.6459\n","Epoch 55/100\n","7/7 [==============================] - 1s 89ms/step - loss: 2.1320 - accuracy: 0.8033\n","Epoch 56/100\n","7/7 [==============================] - 1s 88ms/step - loss: 1.0529 - accuracy: 0.8721\n","Epoch 57/100\n","7/7 [==============================] - 1s 86ms/step - loss: 1.1248 - accuracy: 0.8787\n","Epoch 58/100\n","7/7 [==============================] - 1s 88ms/step - loss: 0.5432 - accuracy: 0.9246\n","Epoch 59/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.1246 - accuracy: 0.9803\n","Epoch 60/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.1187 - accuracy: 0.9770\n","Epoch 61/100\n","7/7 [==============================] - 1s 96ms/step - loss: 0.0570 - accuracy: 0.9934\n","Epoch 62/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.0582 - accuracy: 0.9869\n","Epoch 63/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0356 - accuracy: 0.9869\n","Epoch 64/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.0702 - accuracy: 0.9869\n","Epoch 65/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0574 - accuracy: 0.9934\n","Epoch 66/100\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0688 - accuracy: 0.9934\n","Epoch 67/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0791 - accuracy: 0.9770\n","Epoch 68/100\n","7/7 [==============================] - 1s 93ms/step - loss: 0.0958 - accuracy: 0.9836\n","Epoch 69/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.0297 - accuracy: 0.9934\n","Epoch 70/100\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0561 - accuracy: 0.9902\n","Epoch 71/100\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0897 - accuracy: 0.9836\n","Epoch 72/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0629 - accuracy: 0.9869\n","Epoch 73/100\n","7/7 [==============================] - 1s 88ms/step - loss: 0.0966 - accuracy: 0.9869\n","Epoch 74/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.9781 - accuracy: 0.8918\n","Epoch 75/100\n","7/7 [==============================] - 1s 94ms/step - loss: 0.5783 - accuracy: 0.9049\n","Epoch 76/100\n","7/7 [==============================] - 1s 89ms/step - loss: 0.3866 - accuracy: 0.9574\n","Epoch 77/100\n","7/7 [==============================] - 1s 91ms/step - loss: 0.6002 - accuracy: 0.9148\n","Epoch 78/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.1957 - accuracy: 0.9574\n","Epoch 79/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.1782 - accuracy: 0.9672\n","Epoch 80/100\n","7/7 [==============================] - 1s 87ms/step - loss: 0.2452 - accuracy: 0.9508\n","Epoch 81/100\n","7/7 [==============================] - 1s 84ms/step - loss: 0.2146 - accuracy: 0.9607\n","Epoch 82/100\n","7/7 [==============================] - 1s 97ms/step - loss: 0.2169 - accuracy: 0.9705\n","Epoch 83/100\n","7/7 [==============================] - 1s 89ms/step - loss: 0.0672 - accuracy: 0.9803\n","Epoch 84/100\n","7/7 [==============================] - 1s 90ms/step - loss: 0.1464 - accuracy: 0.9770\n","Epoch 85/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.0835 - accuracy: 0.9902\n","Epoch 86/100\n","7/7 [==============================] - 1s 86ms/step - loss: 0.1208 - accuracy: 0.9869\n","Epoch 87/100\n","7/7 [==============================] - 1s 86ms/step - loss: 1.1758 - accuracy: 0.8885\n","Epoch 88/100\n","7/7 [==============================] - 1s 86ms/step - loss: 4.5988 - accuracy: 0.6689\n","Epoch 89/100\n","7/7 [==============================] - 1s 93ms/step - loss: 1.6898 - accuracy: 0.8492\n","Epoch 90/100\n","7/7 [==============================] - 1s 91ms/step - loss: 12.8693 - accuracy: 0.7115\n","Epoch 91/100\n","7/7 [==============================] - 1s 86ms/step - loss: 4.5180 - accuracy: 0.7836\n","Epoch 92/100\n","7/7 [==============================] - 1s 88ms/step - loss: 5.8560 - accuracy: 0.7639\n","Epoch 93/100\n","7/7 [==============================] - 1s 86ms/step - loss: 10.2832 - accuracy: 0.6197\n","Epoch 94/100\n","7/7 [==============================] - 1s 90ms/step - loss: 11.4641 - accuracy: 0.5311\n","Epoch 95/100\n","7/7 [==============================] - 1s 92ms/step - loss: 23.3001 - accuracy: 0.5115\n","Epoch 96/100\n","7/7 [==============================] - 1s 95ms/step - loss: 11.2195 - accuracy: 0.6361\n","Epoch 97/100\n","7/7 [==============================] - 1s 93ms/step - loss: 6.3190 - accuracy: 0.7049\n","Epoch 98/100\n","7/7 [==============================] - 1s 87ms/step - loss: 4.6353 - accuracy: 0.7410\n","Epoch 99/100\n","7/7 [==============================] - 1s 85ms/step - loss: 1.3792 - accuracy: 0.8459\n","Epoch 100/100\n","7/7 [==============================] - 1s 85ms/step - loss: 1.9429 - accuracy: 0.8525\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x231e71b45e0>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["MLP = mlp(dummy_propertyType_train.shape[1])\n","MLP.fit(Img_array_train, dummy_propertyType_train, epochs = 100, batch_size = 50)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["propertyType_test_pred = np.argmax(MLP.predict(Img_array_test), axis = 1) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def cnn(output_dim):\n","\n","    '''\n","    Creates a convolutional neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Conv2D(16, 3, padding = 'same', activation = tf.nn.relu))\n","    model.add(MaxPooling2D())   \n","    model.add(Flatten())\n","    model.add(Dense(128, activation = 'relu'))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CNN = cnn(dummy_propertyType_train.shape[1])\n","CNN.fit(Img_array_train, dummy_propertyType_train, epochs = 15, batch_size = 50)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
