{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"b5mWiul2qpIW"},"source":["## Mount the Drive, and Change to Google Drive Folder"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20292,"status":"ok","timestamp":1685703332650,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Tbthf1NQqCI_","outputId":"0523dfd5-044d-40e2-ba09-211cfed04eb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount = True)\n","\n","# %cd /content/drive/MyDrive/MSc.-Dissertations/1/Files\n","# %ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sdt1cPGxrIS9"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4983,"status":"ok","timestamp":1685703337623,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"kJuXqpDDXskx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import models, layers, utils, losses\n","from keras.wrappers import scikit_learn\n","from keras.models import *\n","from keras.layers import *\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from keras.utils import np_utils\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix\n","import random\n","import pandas as pd\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"14v7-4Ahre6v"},"source":["## Count the Number of Files, and Take Random Samples from the Image Files"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1685703337958,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"3490JUu9rPbw"},"outputs":[],"source":["# !ls street_view\n","# count how many files and write the filenames into a file\n","# !ls street_view -1 | wc -l \n","# !ls street_view/*.jpg > flist.txt\n","flist = list(pd.read_csv('flist.txt', header = None)[0])\n","\n","# Set seed so sample is reproducible \n","random.seed(99)  # set this to an integer value!!!\n","nsamp = 100\n","flist_sub = random.sample(flist, nsamp)\n","flist = flist_sub\n","\n","# print(flist)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wkzy9pS2sATL"},"source":["## Overview of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Read the `properties` dataset first, and make sure that `property type` is a categorical variable."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1685703338269,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"82aa5d04-bd88-4520-b79f-23c955888237"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>address</th>\n","      <th>propertyType</th>\n","      <th>bedrooms</th>\n","      <th>detailUrl</th>\n","      <th>location_lat</th>\n","      <th>location_lng</th>\n","      <th>property_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...</td>\n","      <td>Terraced</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29986</td>\n","      <td>-1.49446</td>\n","      <td>60d9dd15-c5a0-4d9c-a341-a1d47add49d5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>5, Highgate Lane, Dronfield, Derbyshire S18 1UB</td>\n","      <td>Detached</td>\n","      <td>4.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29135</td>\n","      <td>-1.45975</td>\n","      <td>4a586e80-181a-4b82-b5c3-2d789436bb14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>125, Gosforth Lane, Dronfield, Derbyshire S18 1RB</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29763</td>\n","      <td>-1.47573</td>\n","      <td>93680b6c-237e-44d3-8f40-959a14b80cad</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>80, Shakespeare Crescent, Dronfield, Derbyshir...</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29259</td>\n","      <td>-1.45644</td>\n","      <td>5d49758b-f148-4d06-bbae-3eb23f5c68fb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>21, Gainsborough Road, Dronfield, Derbyshire S...</td>\n","      <td>Detached</td>\n","      <td>NaN</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29740</td>\n","      <td>-1.48503</td>\n","      <td>4645f5eb-de7c-474f-8d7e-b59fa8c55f19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                            address propertyType  \\\n","0           0  12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...     Terraced   \n","1           0    5, Highgate Lane, Dronfield, Derbyshire S18 1UB     Detached   \n","2           0  125, Gosforth Lane, Dronfield, Derbyshire S18 1RB     Detached   \n","3           0  80, Shakespeare Crescent, Dronfield, Derbyshir...     Detached   \n","4           0  21, Gainsborough Road, Dronfield, Derbyshire S...     Detached   \n","\n","   bedrooms                                          detailUrl  location_lat  \\\n","0       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29986   \n","1       4.0  https://www.rightmove.co.uk/house-prices/detai...      53.29135   \n","2       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29763   \n","3       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29259   \n","4       NaN  https://www.rightmove.co.uk/house-prices/detai...      53.29740   \n","\n","   location_lng                           property_id  \n","0      -1.49446  60d9dd15-c5a0-4d9c-a341-a1d47add49d5  \n","1      -1.45975  4a586e80-181a-4b82-b5c3-2d789436bb14  \n","2      -1.47573  93680b6c-237e-44d3-8f40-959a14b80cad  \n","3      -1.45644  5d49758b-f148-4d06-bbae-3eb23f5c68fb  \n","4      -1.48503  4645f5eb-de7c-474f-8d7e-b59fa8c55f19  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["properties = pd.read_csv('properties.csv')\n","properties.propertyType = properties.propertyType.astype('category')\n","properties.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Basic information of the dataset is shown as follows."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1685703338661,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zFHpWHe8ndW6","outputId":"a9a60486-f56c-41ca-d447-5e36dc1dcb3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17550 entries, 0 to 17549\n","Data columns (total 8 columns):\n"," #   Column        Non-Null Count  Dtype   \n","---  ------        --------------  -----   \n"," 0   Unnamed: 0    17550 non-null  int64   \n"," 1   address       17550 non-null  object  \n"," 2   propertyType  17550 non-null  category\n"," 3   bedrooms      11505 non-null  float64 \n"," 4   detailUrl     17550 non-null  object  \n"," 5   location_lat  17550 non-null  float64 \n"," 6   location_lng  17550 non-null  float64 \n"," 7   property_id   17550 non-null  object  \n","dtypes: category(1), float64(3), int64(1), object(3)\n","memory usage: 977.2+ KB\n"]}],"source":["properties.info()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Descriptive statistics of continuous variables are shown as follows."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685703338662,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"8ser64Zzm7Km","outputId":"e959f663-769b-4db4-a546-9201e2fa3f63"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>bedrooms</th>\n","      <th>location_lat</th>\n","      <th>location_lng</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>17550.0</td>\n","      <td>11505.000000</td>\n","      <td>17550.000000</td>\n","      <td>17550.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.0</td>\n","      <td>2.871186</td>\n","      <td>52.912264</td>\n","      <td>-2.330492</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.0</td>\n","      <td>1.010339</td>\n","      <td>1.833830</td>\n","      <td>1.262468</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>50.617080</td>\n","      <td>-4.268950</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.0</td>\n","      <td>2.000000</td>\n","      <td>51.232830</td>\n","      <td>-3.067290</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.0</td>\n","      <td>3.000000</td>\n","      <td>53.095885</td>\n","      <td>-2.658955</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.0</td>\n","      <td>3.000000</td>\n","      <td>53.846760</td>\n","      <td>-1.712750</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.0</td>\n","      <td>6.000000</td>\n","      <td>55.910540</td>\n","      <td>0.719990</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Unnamed: 0      bedrooms  location_lat  location_lng\n","count     17550.0  11505.000000  17550.000000  17550.000000\n","mean          0.0      2.871186     52.912264     -2.330492\n","std           0.0      1.010339      1.833830      1.262468\n","min           0.0      0.000000     50.617080     -4.268950\n","25%           0.0      2.000000     51.232830     -3.067290\n","50%           0.0      3.000000     53.095885     -2.658955\n","75%           0.0      3.000000     53.846760     -1.712750\n","max           0.0      6.000000     55.910540      0.719990"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["properties.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Frequencies of each level of the variable `property type` are obtained as follows."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1685703338663,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"mMG-qHT_8rSr","outputId":"b2ad2fb9-4014-450e-e954-215b4e64db2a"},"outputs":[{"data":{"text/plain":["Detached         4134\n","Semi-Detached    4056\n","Unknown          3900\n","Terraced         3666\n","Flat             1794\n","Name: propertyType, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["properties.propertyType.value_counts()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XDqLkqImshZy"},"source":["## A Subset of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685703338664,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj"},"outputs":[],"source":["flist_id = list(map(lambda string: string[16 : -4], flist))\n","properties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Dictionaries are created to link `property ID` with our variables of interest."]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":146820,"status":"ok","timestamp":1685703485474,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"ZdHCLGjmuQJA"},"outputs":[],"source":["dic_propID_imgArray = dict(zip(flist_id, list(map(lambda x: np.array(Image.open(x)), flist)))) # dictionary of RGB values in each pixel\n","dic_propID_propType = dict(zip(flist_id, properties_sub.propertyType)) # dictionary of property types\n","dic_address_propID = dict(zip(properties_sub.address, flist_id))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["Img_array_train, Img_array_test, propertyType_train, propertyType_test = train_test_split(\n","    np.array(list(map(dic_propID_imgArray.get, flist_id))), # RGB values in each pixel\n","    np.array(list(map(dic_propID_propType.get, flist_id))), # property types\n","    test_size = 0.3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["For categorical variables, one-hot encoder is introduced."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def onehot(variable):\n","\n","    '''\n","    Constructs one-hot encoder for a specified categorical variable.\n","\n","    Parameter:\n","    variable: A categorical variable.\n","    \n","    Returns:\n","    Dummy encoding of the categorical variable.\n","    '''\n","\n","    onehot_encoder = LabelEncoder()\n","    onehot_encoder.fit(variable)\n","    encoded_variable = onehot_encoder.transform(variable)\n","    dummy_variable = np_utils.to_categorical(encoded_variable)\n","    return dummy_variable"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":70,"status":"ok","timestamp":1685703485477,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"_bFYcWMtuQJA"},"outputs":[],"source":["dummy_propertyType_train = pd.get_dummies(propertyType_train)\n","dummy_propertyType_test = pd.get_dummies(propertyType_test)\n","propertyType_test_fac = np.argmax(np.array(dummy_propertyType_test), axis = 1) "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CzlhhsNtuQJB"},"source":["## Multi-Class Classification Using Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Multi-Layer Perceptron (MLP) model"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1685703485479,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"cVOv_GReuQJB"},"outputs":[],"source":["def mlp(output_dim):\n","\n","    '''\n","    Creates a multi-layer perceptron neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Flatten())\n","    # model.add(Dense(100, activation = tf.nn.leaky_relu))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6071,"status":"ok","timestamp":1685703491525,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zz6qw9ZvuQJB","outputId":"533c854e-87ca-4e7e-c441-1391c50bff64"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","24/24 [==============================] - 3s 70ms/step - loss: 96.9952 - accuracy: 0.2014\n","Epoch 2/100\n","24/24 [==============================] - 2s 75ms/step - loss: 48.1270 - accuracy: 0.2114\n","Epoch 3/100\n","24/24 [==============================] - 2s 76ms/step - loss: 26.0572 - accuracy: 0.2800\n","Epoch 4/100\n","24/24 [==============================] - 2s 82ms/step - loss: 31.4424 - accuracy: 0.2829\n","Epoch 5/100\n","24/24 [==============================] - 2s 69ms/step - loss: 23.5617 - accuracy: 0.2843\n","Epoch 6/100\n","24/24 [==============================] - 2s 77ms/step - loss: 18.0167 - accuracy: 0.3429\n","Epoch 7/100\n","24/24 [==============================] - 2s 79ms/step - loss: 21.0920 - accuracy: 0.3100\n","Epoch 8/100\n","24/24 [==============================] - 2s 70ms/step - loss: 12.6432 - accuracy: 0.3586\n","Epoch 9/100\n","24/24 [==============================] - 2s 71ms/step - loss: 16.6644 - accuracy: 0.3757\n","Epoch 10/100\n","24/24 [==============================] - 2s 71ms/step - loss: 19.7032 - accuracy: 0.3586\n","Epoch 11/100\n","24/24 [==============================] - 2s 75ms/step - loss: 14.1763 - accuracy: 0.3757\n","Epoch 12/100\n","24/24 [==============================] - 2s 71ms/step - loss: 11.8387 - accuracy: 0.3857\n","Epoch 13/100\n","24/24 [==============================] - 2s 76ms/step - loss: 18.3742 - accuracy: 0.3571\n","Epoch 14/100\n","24/24 [==============================] - 2s 72ms/step - loss: 14.9023 - accuracy: 0.3757\n","Epoch 15/100\n","24/24 [==============================] - 2s 72ms/step - loss: 9.8402 - accuracy: 0.4057\n","Epoch 16/100\n","24/24 [==============================] - 2s 81ms/step - loss: 9.3425 - accuracy: 0.4471\n","Epoch 17/100\n","24/24 [==============================] - 2s 72ms/step - loss: 22.6112 - accuracy: 0.3600\n","Epoch 18/100\n","24/24 [==============================] - 2s 75ms/step - loss: 18.2312 - accuracy: 0.3714\n","Epoch 19/100\n","24/24 [==============================] - 2s 71ms/step - loss: 10.3501 - accuracy: 0.4557\n","Epoch 20/100\n","24/24 [==============================] - 2s 71ms/step - loss: 8.9764 - accuracy: 0.4729\n","Epoch 21/100\n","24/24 [==============================] - 2s 72ms/step - loss: 9.2080 - accuracy: 0.4657\n","Epoch 22/100\n","24/24 [==============================] - 2s 72ms/step - loss: 11.1643 - accuracy: 0.4257\n","Epoch 23/100\n","24/24 [==============================] - 2s 74ms/step - loss: 17.3531 - accuracy: 0.3671\n","Epoch 24/100\n","24/24 [==============================] - 2s 72ms/step - loss: 20.6075 - accuracy: 0.3886\n","Epoch 25/100\n","24/24 [==============================] - 2s 71ms/step - loss: 23.9988 - accuracy: 0.3914\n","Epoch 26/100\n","24/24 [==============================] - 2s 75ms/step - loss: 14.0873 - accuracy: 0.4100\n","Epoch 27/100\n","24/24 [==============================] - 2s 71ms/step - loss: 10.3641 - accuracy: 0.4643\n","Epoch 28/100\n","24/24 [==============================] - 2s 71ms/step - loss: 9.1332 - accuracy: 0.4829\n","Epoch 29/100\n","24/24 [==============================] - 2s 75ms/step - loss: 13.6337 - accuracy: 0.4400\n","Epoch 30/100\n","24/24 [==============================] - 2s 71ms/step - loss: 11.5634 - accuracy: 0.4657\n","Epoch 31/100\n","24/24 [==============================] - 2s 75ms/step - loss: 11.2022 - accuracy: 0.5229\n","Epoch 32/100\n","24/24 [==============================] - 2s 71ms/step - loss: 9.5957 - accuracy: 0.4871\n","Epoch 33/100\n","24/24 [==============================] - 2s 74ms/step - loss: 13.6376 - accuracy: 0.4514\n","Epoch 34/100\n","24/24 [==============================] - 2s 72ms/step - loss: 14.0189 - accuracy: 0.4814\n","Epoch 35/100\n","24/24 [==============================] - 2s 74ms/step - loss: 24.6353 - accuracy: 0.3986\n","Epoch 36/100\n","24/24 [==============================] - 2s 72ms/step - loss: 10.2908 - accuracy: 0.4986\n","Epoch 37/100\n","24/24 [==============================] - 2s 71ms/step - loss: 10.2903 - accuracy: 0.5114\n","Epoch 38/100\n","24/24 [==============================] - 2s 75ms/step - loss: 12.5045 - accuracy: 0.4829\n","Epoch 39/100\n","24/24 [==============================] - 2s 71ms/step - loss: 10.1977 - accuracy: 0.5257\n","Epoch 40/100\n","24/24 [==============================] - 2s 75ms/step - loss: 9.5114 - accuracy: 0.4829\n","Epoch 41/100\n","24/24 [==============================] - 2s 71ms/step - loss: 8.6539 - accuracy: 0.5171\n","Epoch 42/100\n","24/24 [==============================] - 2s 72ms/step - loss: 9.6444 - accuracy: 0.4971\n","Epoch 43/100\n","24/24 [==============================] - 2s 75ms/step - loss: 14.0891 - accuracy: 0.4686\n","Epoch 44/100\n","24/24 [==============================] - 2s 71ms/step - loss: 12.6914 - accuracy: 0.4957\n","Epoch 45/100\n","24/24 [==============================] - 2s 74ms/step - loss: 11.5758 - accuracy: 0.4929\n","Epoch 46/100\n","24/24 [==============================] - 2s 71ms/step - loss: 12.2827 - accuracy: 0.5014\n","Epoch 47/100\n","24/24 [==============================] - 2s 72ms/step - loss: 17.2626 - accuracy: 0.4657\n","Epoch 48/100\n","24/24 [==============================] - 2s 75ms/step - loss: 10.9231 - accuracy: 0.5043\n","Epoch 49/100\n","24/24 [==============================] - 2s 72ms/step - loss: 16.5279 - accuracy: 0.4586\n","Epoch 50/100\n","24/24 [==============================] - 2s 74ms/step - loss: 8.8720 - accuracy: 0.5114\n","Epoch 51/100\n","24/24 [==============================] - 2s 72ms/step - loss: 11.7479 - accuracy: 0.5057\n","Epoch 52/100\n","24/24 [==============================] - 2s 75ms/step - loss: 9.7465 - accuracy: 0.5143\n","Epoch 53/100\n","24/24 [==============================] - 2s 71ms/step - loss: 14.5518 - accuracy: 0.5143\n","Epoch 54/100\n","24/24 [==============================] - 2s 71ms/step - loss: 19.5421 - accuracy: 0.5257\n","Epoch 55/100\n","24/24 [==============================] - 2s 74ms/step - loss: 12.2665 - accuracy: 0.5114\n","Epoch 56/100\n","24/24 [==============================] - 2s 72ms/step - loss: 8.8712 - accuracy: 0.5329\n","Epoch 57/100\n","24/24 [==============================] - 2s 74ms/step - loss: 11.6393 - accuracy: 0.4871\n","Epoch 58/100\n","24/24 [==============================] - 2s 71ms/step - loss: 13.4113 - accuracy: 0.4729\n","Epoch 59/100\n","24/24 [==============================] - 2s 74ms/step - loss: 20.0577 - accuracy: 0.4343\n","Epoch 60/100\n","24/24 [==============================] - 2s 71ms/step - loss: 11.8069 - accuracy: 0.5171\n","Epoch 61/100\n","24/24 [==============================] - 2s 72ms/step - loss: 10.4735 - accuracy: 0.5371\n","Epoch 62/100\n","24/24 [==============================] - 2s 74ms/step - loss: 15.2204 - accuracy: 0.4529\n","Epoch 63/100\n","24/24 [==============================] - 2s 71ms/step - loss: 12.3058 - accuracy: 0.4957\n","Epoch 64/100\n","24/24 [==============================] - 2s 73ms/step - loss: 13.5385 - accuracy: 0.4629\n","Epoch 65/100\n","24/24 [==============================] - 2s 71ms/step - loss: 14.1456 - accuracy: 0.4757\n","Epoch 66/100\n","24/24 [==============================] - 2s 76ms/step - loss: 13.9414 - accuracy: 0.4743\n","Epoch 67/100\n","24/24 [==============================] - 2s 71ms/step - loss: 28.0448 - accuracy: 0.4386\n","Epoch 68/100\n","24/24 [==============================] - 2s 72ms/step - loss: 18.1344 - accuracy: 0.4514\n","Epoch 69/100\n","24/24 [==============================] - 2s 74ms/step - loss: 14.6025 - accuracy: 0.4857\n","Epoch 70/100\n","24/24 [==============================] - 2s 71ms/step - loss: 7.7021 - accuracy: 0.5671\n","Epoch 71/100\n","24/24 [==============================] - 2s 74ms/step - loss: 15.2635 - accuracy: 0.5114\n","Epoch 72/100\n","24/24 [==============================] - 2s 72ms/step - loss: 9.1591 - accuracy: 0.5671\n","Epoch 73/100\n","24/24 [==============================] - 2s 74ms/step - loss: 10.7122 - accuracy: 0.5329\n","Epoch 74/100\n","24/24 [==============================] - 2s 72ms/step - loss: 9.4036 - accuracy: 0.5500\n","Epoch 75/100\n","24/24 [==============================] - 2s 71ms/step - loss: 10.5320 - accuracy: 0.5386\n","Epoch 76/100\n","24/24 [==============================] - 2s 74ms/step - loss: 8.8907 - accuracy: 0.5486\n","Epoch 77/100\n","24/24 [==============================] - 2s 73ms/step - loss: 11.8924 - accuracy: 0.5243\n","Epoch 78/100\n","24/24 [==============================] - 2s 77ms/step - loss: 9.3755 - accuracy: 0.5386\n","Epoch 79/100\n","24/24 [==============================] - 2s 72ms/step - loss: 11.4697 - accuracy: 0.5086\n","Epoch 80/100\n","24/24 [==============================] - 2s 74ms/step - loss: 9.9235 - accuracy: 0.5457\n","Epoch 81/100\n","24/24 [==============================] - 2s 72ms/step - loss: 19.6373 - accuracy: 0.4571\n","Epoch 82/100\n","24/24 [==============================] - 2s 75ms/step - loss: 16.5452 - accuracy: 0.5314\n","Epoch 83/100\n","24/24 [==============================] - 2s 75ms/step - loss: 12.9439 - accuracy: 0.5214\n","Epoch 84/100\n","24/24 [==============================] - 2s 72ms/step - loss: 18.0902 - accuracy: 0.4971\n","Epoch 85/100\n","24/24 [==============================] - 2s 75ms/step - loss: 11.0494 - accuracy: 0.5257\n","Epoch 86/100\n","24/24 [==============================] - 2s 72ms/step - loss: 14.2159 - accuracy: 0.5400\n","Epoch 87/100\n","24/24 [==============================] - 2s 74ms/step - loss: 14.7429 - accuracy: 0.5200\n","Epoch 88/100\n","24/24 [==============================] - 2s 71ms/step - loss: 8.4885 - accuracy: 0.5686\n","Epoch 89/100\n","24/24 [==============================] - 2s 74ms/step - loss: 15.9434 - accuracy: 0.4900\n","Epoch 90/100\n","24/24 [==============================] - 2s 72ms/step - loss: 8.1037 - accuracy: 0.5643\n","Epoch 91/100\n","24/24 [==============================] - 2s 74ms/step - loss: 20.6168 - accuracy: 0.4557\n","Epoch 92/100\n","24/24 [==============================] - 2s 71ms/step - loss: 27.3893 - accuracy: 0.4429\n","Epoch 93/100\n","24/24 [==============================] - 2s 74ms/step - loss: 14.8862 - accuracy: 0.5114\n","Epoch 94/100\n","24/24 [==============================] - 2s 71ms/step - loss: 11.3758 - accuracy: 0.5329\n","Epoch 95/100\n","24/24 [==============================] - 2s 74ms/step - loss: 12.5243 - accuracy: 0.5057\n","Epoch 96/100\n","24/24 [==============================] - 2s 71ms/step - loss: 9.5554 - accuracy: 0.5600\n","Epoch 97/100\n","24/24 [==============================] - 2s 71ms/step - loss: 8.7476 - accuracy: 0.5600\n","Epoch 98/100\n","24/24 [==============================] - 2s 75ms/step - loss: 11.5207 - accuracy: 0.5357\n","Epoch 99/100\n","24/24 [==============================] - 2s 72ms/step - loss: 13.2770 - accuracy: 0.5186\n","Epoch 100/100\n","24/24 [==============================] - 2s 74ms/step - loss: 13.3909 - accuracy: 0.5271\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1ba467bbdf0>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["MLP = mlp(dummy_propertyType_train.shape[1])\n","MLP.fit(Img_array_train, dummy_propertyType_train, epochs = 100, batch_size = 30)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["10/10 [==============================] - 0s 28ms/step\n"]}],"source":["propertyType_test_pred = np.argmax(MLP.predict(Img_array_test), axis = 1) "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["array([[ 5,  3, 22, 13, 20],\n","       [ 5,  0, 10,  9,  7],\n","       [ 9,  1, 19, 27, 17],\n","       [ 6,  3, 24, 22, 23],\n","       [ 5,  0, 14, 15, 21]], dtype=int64)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["def cnn(output_dim):\n","\n","    '''\n","    Creates a convolutional neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Conv2D(16, 3, padding = 'same', activation = tf.nn.relu))\n","    model.add(MaxPooling2D())   \n","    model.add(Flatten())\n","    model.add(Dense(128, activation = 'relu'))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","7/7 [==============================] - 38s 4s/step - loss: 48.5016 - accuracy: 0.2300\n","Epoch 2/10\n","7/7 [==============================] - 29s 4s/step - loss: 25.8775 - accuracy: 0.2086\n","Epoch 3/10\n","7/7 [==============================] - 26s 4s/step - loss: 4.8430 - accuracy: 0.2614\n","Epoch 4/10\n","7/7 [==============================] - 25s 4s/step - loss: 2.8596 - accuracy: 0.3557\n","Epoch 5/10\n","7/7 [==============================] - 28s 4s/step - loss: 1.6774 - accuracy: 0.2771\n","Epoch 6/10\n","7/7 [==============================] - 35s 5s/step - loss: 1.4438 - accuracy: 0.4086\n","Epoch 7/10\n","7/7 [==============================] - 29s 4s/step - loss: 1.2611 - accuracy: 0.4729\n","Epoch 8/10\n","7/7 [==============================] - 28s 4s/step - loss: 1.1687 - accuracy: 0.5271\n","Epoch 9/10\n","7/7 [==============================] - 26s 4s/step - loss: 1.0885 - accuracy: 0.5643\n","Epoch 10/10\n","7/7 [==============================] - 26s 4s/step - loss: 1.0044 - accuracy: 0.5771\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1ba4fa0df60>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["CNN = cnn(dummy_propertyType_train.shape[1])\n","CNN.fit(Img_array_train, dummy_propertyType_train, epochs = 10, batch_size = 100)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
