{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"b5mWiul2qpIW"},"source":["## Mount the Drive, and Change to Google Drive Folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20292,"status":"ok","timestamp":1685703332650,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Tbthf1NQqCI_","outputId":"0523dfd5-044d-40e2-ba09-211cfed04eb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount = True)\n","\n","# %cd /content/drive/MyDrive/MSc.-Dissertations/1/Files\n","# %ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sdt1cPGxrIS9"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4983,"status":"ok","timestamp":1685703337623,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"kJuXqpDDXskx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import models, layers, utils, losses, optimizers\n","from keras.wrappers import scikit_learn\n","from keras.models import *\n","from keras.layers import *\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from keras.utils import np_utils, image_dataset_from_directory\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix\n","\n","import random\n","import pandas as pd\n","import numpy as np\n","from PIL import Image, ImageFilter\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"14v7-4Ahre6v"},"source":["## Count the Number of Files, and Take Random Samples from the Image Files"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1685703337958,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"3490JUu9rPbw"},"outputs":[],"source":["# !ls street_view\n","# count how many files and write the filenames into a file\n","# !ls street_view -1 | wc -l \n","# !ls street_view/*.jpg > flist.txt\n","flist_old = list(pd.read_csv('flist.txt', header = None)[0])\n","flist = []\n","change_names = list(map(lambda x: flist.append(f'street_view/{x}'), flist_old))\n","\n","# Set seed so sample is reproducible \n","# random.seed(99)  # set this to an integer value!!!\n","# nsamp = 100\n","# flist_sub = random.sample(flist, nsamp)\n","# flist = flist_sub\n","\n","# print(flist)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wkzy9pS2sATL"},"source":["## Overview of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Read the `properties` dataset first, and make sure that `property type` is a categorical variable."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1685703338269,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"82aa5d04-bd88-4520-b79f-23c955888237"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>address</th>\n","      <th>propertyType</th>\n","      <th>bedrooms</th>\n","      <th>detailUrl</th>\n","      <th>location_lat</th>\n","      <th>location_lng</th>\n","      <th>property_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...</td>\n","      <td>Terraced</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29986</td>\n","      <td>-1.49446</td>\n","      <td>60d9dd15-c5a0-4d9c-a341-a1d47add49d5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>5, Highgate Lane, Dronfield, Derbyshire S18 1UB</td>\n","      <td>Detached</td>\n","      <td>4.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29135</td>\n","      <td>-1.45975</td>\n","      <td>4a586e80-181a-4b82-b5c3-2d789436bb14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>125, Gosforth Lane, Dronfield, Derbyshire S18 1RB</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29763</td>\n","      <td>-1.47573</td>\n","      <td>93680b6c-237e-44d3-8f40-959a14b80cad</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>80, Shakespeare Crescent, Dronfield, Derbyshir...</td>\n","      <td>Detached</td>\n","      <td>3.0</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29259</td>\n","      <td>-1.45644</td>\n","      <td>5d49758b-f148-4d06-bbae-3eb23f5c68fb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>21, Gainsborough Road, Dronfield, Derbyshire S...</td>\n","      <td>Detached</td>\n","      <td>NaN</td>\n","      <td>https://www.rightmove.co.uk/house-prices/detai...</td>\n","      <td>53.29740</td>\n","      <td>-1.48503</td>\n","      <td>4645f5eb-de7c-474f-8d7e-b59fa8c55f19</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                            address propertyType  \\\n","0           0  12, Gorsey Brigg, Dronfield Woodhouse, Dronfie...     Terraced   \n","1           0    5, Highgate Lane, Dronfield, Derbyshire S18 1UB     Detached   \n","2           0  125, Gosforth Lane, Dronfield, Derbyshire S18 1RB     Detached   \n","3           0  80, Shakespeare Crescent, Dronfield, Derbyshir...     Detached   \n","4           0  21, Gainsborough Road, Dronfield, Derbyshire S...     Detached   \n","\n","   bedrooms                                          detailUrl  location_lat  \\\n","0       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29986   \n","1       4.0  https://www.rightmove.co.uk/house-prices/detai...      53.29135   \n","2       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29763   \n","3       3.0  https://www.rightmove.co.uk/house-prices/detai...      53.29259   \n","4       NaN  https://www.rightmove.co.uk/house-prices/detai...      53.29740   \n","\n","   location_lng                           property_id  \n","0      -1.49446  60d9dd15-c5a0-4d9c-a341-a1d47add49d5  \n","1      -1.45975  4a586e80-181a-4b82-b5c3-2d789436bb14  \n","2      -1.47573  93680b6c-237e-44d3-8f40-959a14b80cad  \n","3      -1.45644  5d49758b-f148-4d06-bbae-3eb23f5c68fb  \n","4      -1.48503  4645f5eb-de7c-474f-8d7e-b59fa8c55f19  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["properties = pd.read_csv('properties.csv')\n","properties_juny12 = pd.read_csv('properties_juny12.csv')\n","properties_full = pd.concat([properties, properties_juny12])\n","properties = properties_full\n","properties.propertyType = properties.propertyType.astype('category')\n","properties.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XDqLkqImshZy"},"source":["## A Subset of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples."]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685703338664,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj"},"outputs":[],"source":["flist_id = list(map(lambda string: string[16 : -4], flist))\n","properties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\n","properties_sub = properties_sub.drop_duplicates(['location_lat', 'location_lng'])\n","flist_id = list(properties_sub.property_id)\n","flist_new = []\n","change_names_new = list(map(lambda x: flist_new.append(f'street_view/gsv_{x}.jpg'), flist_id))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Unexpected exception formatting exception. Falling back to standard exception\n"]},{"name":"stderr","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"C:\\Users\\Robin\\AppData\\Local\\Temp\\ipykernel_11280\\52720562.py\", line -1, in <module>\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n","    frames.append(self.format_record(r))\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n","    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n","    pieces = self.included_pieces\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n","    pos = scope_pieces.index(self.executing_piece)\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n","    value = obj.__dict__[self.func.__name__] = self.func(obj)\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n","    return only(\n","  File \"c:\\ProgramData\\anaconda3\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n","    raise NotOneValueFound('Expected one value, found 0')\n","executing.executing.NotOneValueFound: Expected one value, found 0\n"]}],"source":["import os\n","\n","# List of image directories\n","image_dirs = list(map(lambda string: string[0 : 12], flist_new))\n","\n","# List of files to keep\n","files_to_keep = list(map(lambda string: string[12 : ], flist_new))\n","\n","# Remove files not in the list\n","for image_dir in image_dirs:\n","    for filename in os.listdir(image_dir):\n","        if filename not in files_to_keep:\n","            os.remove(os.path.join(image_dir, filename))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import shutil\n","\n","# List of image directories and corresponding labels\n","image_dirs = ['dir1', 'dir2', 'dir3']\n","labels = ['label1', 'label2', 'label3']\n","\n","# Create folders for each label\n","for label in labels:\n","    os.makedirs(label, exist_ok = True)\n","\n","# Move images to corresponding folders\n","for i, image_dir in enumerate(image_dirs):\n","    for filename in os.listdir(image_dir):\n","        if filename.endswith('.jpg'):\n","            shutil.move(os.path.join(image_dir, filename), os.path.join(labels[i], filename))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["flist_train, flist_test, propertyType_train, propertyType_test = train_test_split(\n","    flist_new, # image directories\n","    properties_sub.propertyType, # property types\n","    test_size = 0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Img_list_train = list(map(lambda x: np.asarray(Image.open(x).resize((128, 128), Image.LANCZOS).filter(ImageFilter.FIND_EDGES)), flist_train))\n","Img_list_test = list(map(lambda x: np.asarray(Image.open(x).resize((128, 128), Image.LANCZOS).filter(ImageFilter.FIND_EDGES)), flist_test))\n","Img_array_train = np.asarray(Img_list_train)\n","Img_array_test = np.asarray(Img_list_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["For categorical variables, one-hot encoder is introduced."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":70,"status":"ok","timestamp":1685703485477,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"_bFYcWMtuQJA"},"outputs":[],"source":["dummy_propertyType_train = pd.get_dummies(propertyType_train)\n","dummy_propertyType_test = pd.get_dummies(propertyType_test)\n","propertyType_test_fac = np.argmax(np.array(dummy_propertyType_test), axis = 1) "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CzlhhsNtuQJB"},"source":["## Multi-Class Classification Using Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Multi-Layer Perceptron (MLP) model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1685703485479,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"cVOv_GReuQJB"},"outputs":[],"source":["def mlp(output_dim):\n","\n","    '''\n","    Creates a multi-layer perceptron neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation = tf.nn.leaky_relu))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    loss = keras.losses.CategoricalCrossentropy()\n","    weights = np.array(len(propertyType_train) / propertyType_train.value_counts())\n","    loss.weighted = weights\n","    model.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6071,"status":"ok","timestamp":1685703491525,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zz6qw9ZvuQJB","outputId":"533c854e-87ca-4e7e-c441-1391c50bff64"},"outputs":[],"source":["MLP = mlp(dummy_propertyType_train.shape[1])\n","MLP.fit(ImageDataGenerator().flow(Img_array_train, dummy_propertyType_train, batch_size = 256),\n","        epochs = 32, batch_size = 64, \n","        validation_data = ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["propertyType_test_pred_MLP = np.argmax(MLP.predict(Img_array_test), axis = 1) \n","MLP.evaluate(ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred_MLP)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def cnn(output_dim):\n","\n","    '''\n","    Creates a convolutional neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Conv2D(8, (7, 7), padding = 'same', activation = tf.nn.leaky_relu))\n","    model.add(Conv2D(4, (3, 3), padding = 'same', activation = tf.nn.leaky_relu))\n","    model.add(MaxPooling2D()) \n","    model.add(Flatten())\n","    model.add(Dense(16, activation = tf.nn.leaky_relu))\n","    # model.add(Dropout(.5))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    loss = keras.losses.CategoricalCrossentropy()\n","    weights = np.array(len(propertyType_train) / propertyType_train.value_counts())\n","    loss.weighted = weights\n","    model.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CNN = cnn(dummy_propertyType_train.shape[1])\n","CNN.fit(ImageDataGenerator().flow(Img_array_train, dummy_propertyType_train, batch_size = 32), \n","        epochs = 32, batch_size = 64, \n","        validation_data = ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 32))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["propertyType_test_pred_CNN = np.argmax(CNN.predict(Img_array_test), axis = 1) \n","CNN.evaluate(ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred_CNN)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import dill\n","# dill.dump_session('Presetting.pkl')\n","# # dill.load_session('Presetting.pkl')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
