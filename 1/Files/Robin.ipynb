{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"b5mWiul2qpIW"},"source":["## Mount the Drive, and Change to Google Drive Folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20292,"status":"ok","timestamp":1685703332650,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Tbthf1NQqCI_","outputId":"0523dfd5-044d-40e2-ba09-211cfed04eb1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount = True)\n","\n","# %cd /content/drive/MyDrive/MSc.-Dissertations/1/Files\n","# %ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sdt1cPGxrIS9"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4983,"status":"ok","timestamp":1685703337623,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"kJuXqpDDXskx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras import models, layers, utils, losses, optimizers\n","from keras.wrappers import scikit_learn\n","from keras.models import *\n","from keras.layers import *\n","from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n","from keras.utils import np_utils, image_dataset_from_directory\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import confusion_matrix\n","\n","import random\n","import pandas as pd\n","import numpy as np\n","from PIL import Image, ImageFilter\n","import matplotlib.pyplot as plt"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"14v7-4Ahre6v"},"source":["## Count the Number of Files, and Take Random Samples from the Image Files"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1685703337958,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"3490JUu9rPbw"},"outputs":[],"source":["# !ls street_view\n","# count how many files and write the filenames into a file\n","# !ls street_view -1 | wc -l \n","# !ls street_view/*.jpg > flist.txt\n","flist_old = list(pd.read_csv('flist.txt', header = None)[0])\n","flist = []\n","change_names = list(map(lambda x: flist.append(f'street_view/{x}'), flist_old))\n","\n","# Set seed so sample is reproducible \n","# random.seed(99)  # set this to an integer value!!!\n","# nsamp = 100\n","# flist_sub = random.sample(flist, nsamp)\n","# flist = flist_sub\n","\n","# print(flist)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Wkzy9pS2sATL"},"source":["## Overview of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Read the `properties` dataset first, and make sure that `property type` is a categorical variable."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1685703338269,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"YUl8gDe9jXof","outputId":"82aa5d04-bd88-4520-b79f-23c955888237"},"outputs":[],"source":["properties = pd.read_csv('properties.csv')\n","properties_juny12 = pd.read_csv('properties_juny12.csv')\n","properties_full = pd.concat([properties, properties_juny12])\n","properties = properties_full\n","properties.propertyType = properties.propertyType.astype('category')\n","properties.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XDqLkqImshZy"},"source":["## A Subset of the `properties` Dataset"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["As random samples of images have been obtained previously, a subset of the whole `properties` dataset could hence be formulated by selecting the rows of the whole `properties` dataset corresponding to the selected samples."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1685703338664,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"Nqmh9e2Mofpj"},"outputs":[],"source":["flist_id = list(map(lambda string: string[16 : -4], flist))\n","properties_sub = pd.DataFrame(properties.loc[properties['property_id'].isin(flist_id)])\n","properties_sub = properties_sub.drop_duplicates(['location_lat', 'location_lng'])\n","flist_id = list(properties_sub.property_id)\n","flist_new = []\n","change_names_new = list(map(lambda x: flist_new.append(f'street_view/gsv_{x}.jpg'), flist_id))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["The original data should be splitted into training and testing sets, and the testing set contains 30% of the original data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["flist_train, flist_test, propertyType_train, propertyType_test = train_test_split(\n","    flist_new, # image directories\n","    properties_sub.propertyType, # property types\n","    test_size = 0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Img_list_train = list(map(lambda x: np.asarray(Image.open(x).resize((128, 128), Image.LANCZOS).filter(ImageFilter.FIND_EDGES)), flist_train))\n","Img_list_test = list(map(lambda x: np.asarray(Image.open(x).resize((128, 128), Image.LANCZOS).filter(ImageFilter.FIND_EDGES)), flist_test))\n","Img_array_train = np.asarray(Img_list_train)\n","Img_array_test = np.asarray(Img_list_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["For categorical variables, one-hot encoder is introduced."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":70,"status":"ok","timestamp":1685703485477,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"_bFYcWMtuQJA"},"outputs":[],"source":["dummy_propertyType_train = pd.get_dummies(propertyType_train)\n","dummy_propertyType_test = pd.get_dummies(propertyType_test)\n","propertyType_test_fac = np.argmax(np.array(dummy_propertyType_test), axis = 1) "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CzlhhsNtuQJB"},"source":["## Multi-Class Classification Using Neural Network"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Multi-Layer Perceptron (MLP) model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1685703485479,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"cVOv_GReuQJB"},"outputs":[],"source":["def mlp(output_dim):\n","\n","    '''\n","    Creates a multi-layer perceptron neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation = tf.nn.leaky_relu))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    loss = keras.losses.CategoricalCrossentropy()\n","    weights = np.array(len(propertyType_train) / propertyType_train.value_counts())\n","    loss.weighted = weights\n","    model.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6071,"status":"ok","timestamp":1685703491525,"user":{"displayName":"Siwang Lam (Robin)","userId":"07119757220663994168"},"user_tz":-60},"id":"zz6qw9ZvuQJB","outputId":"533c854e-87ca-4e7e-c441-1391c50bff64"},"outputs":[],"source":["MLP = mlp(dummy_propertyType_train.shape[1])\n","MLP.fit(ImageDataGenerator().flow(Img_array_train, dummy_propertyType_train, batch_size = 256),\n","        epochs = 32, batch_size = 64, \n","        validation_data = ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["propertyType_test_pred_MLP = np.argmax(MLP.predict(Img_array_test), axis = 1) \n","MLP.evaluate(ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred_MLP)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Convolutional Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def cnn(output_dim):\n","\n","    '''\n","    Creates a convolutional neural network model without hidden layers.\n","\n","    Parameter:\n","    output_dim (int): The number of output classes.\n","    \n","    Returns:\n","    A compiled Keras model.\n","    '''\n","\n","    model = Sequential()\n","    model.add(Rescaling(1. / 255))\n","    model.add(Conv2D(8, (7, 7), padding = 'same', activation = tf.nn.leaky_relu))\n","    model.add(Conv2D(4, (3, 3), padding = 'same', activation = tf.nn.leaky_relu))\n","    model.add(MaxPooling2D()) \n","    model.add(Flatten())\n","    model.add(Dense(16, activation = tf.nn.leaky_relu))\n","    # model.add(Dropout(.5))\n","    model.add(Dense(output_dim, activation = tf.nn.softmax))\n","    loss = keras.losses.CategoricalCrossentropy()\n","    weights = np.array(len(propertyType_train) / propertyType_train.value_counts())\n","    loss.weighted = weights\n","    model.compile(loss = loss, optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["CNN = cnn(dummy_propertyType_train.shape[1])\n","CNN.fit(ImageDataGenerator().flow(Img_array_train, dummy_propertyType_train, batch_size = 32), \n","        epochs = 32, batch_size = 64, \n","        validation_data = ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 32))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["propertyType_test_pred_CNN = np.argmax(CNN.predict(Img_array_test), axis = 1) \n","CNN.evaluate(ImageDataGenerator().flow(Img_array_test, dummy_propertyType_test, batch_size = 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["confusion_matrix(propertyType_test_fac, propertyType_test_pred_CNN)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import dill\n","# dill.dump_session('Presetting.pkl')\n","# # dill.load_session('Presetting.pkl')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
